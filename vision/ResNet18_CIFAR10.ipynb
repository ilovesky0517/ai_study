{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e60480-d5fa-4884-8076-ba67fba4d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **ResNet18 with CIFAR-10 — 학습/추론/시각화**\n",
    "\n",
    "## 학습 목표\n",
    "- Residual Connection(잔차 연결)의 구조와 원리를 이해하고, ResNet-18 모델을 CIFAR-10 이미지 분류 작업에 맞게 구현 및 최적화할 수 있도록 실습합니다.\n",
    "- 데이터 전처리부터 모델 학습, 성능 평가, 그리고 Class Activation Map(CAM) 등을 활용한 추론 결과 시각화까지의 ResNet 파이프라인 전 과정을 익힙니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 구성 개요\n",
    "1. **CIFAR-10 로드** + 입력 이미지 크기 확인\n",
    "2. **ResNet18(CIFAR-friendly)** 구성\n",
    "3. **학습(Training)** + 체크포인트 저장/재개(있으면 +10 epoch, 없으면 20 epoch)\n",
    "4. **추론(Inference)** + 예측/신뢰도 확인\n",
    "5. **Confusion Matrix / 클래스별 정확도 / 오분류 샘플** 분석\n",
    "6. **Activation Map** 시각화 (layer1 vs layer4 비교)\n",
    "7. **Conv Kernel** 시각화 (초기/중간 레이어)\n",
    "8. **Grad-CAM** 시각화 (Top-K 정분류 + Top-K 오분류: 원본과 Overlay 함께)\n",
    "9. (추가 실습) **Receptive Field** 근사 계산 + 의미 설명\n",
    "10. (추가 실습) **Embedding(t-SNE)** 시각화\n",
    "11. (추가 실습) **ONNX Export + 모델 구조 출력** (Netron 비교용)\n",
    "\n",
    "> 권장 실행: 위에서 아래로 순차 실행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a198f-7b4d-46b5-8251-036be84f3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def ensure_package(pkg_name: str, import_name=None):\n",
    "    \"\"\"\n",
    "    패키지 설치 여부를 확인하고, 설치되어 있지 않으면 설치합니다.\n",
    "    \"\"\"\n",
    "    name = import_name or pkg_name\n",
    "    # 패키지가 설치되어 있는지 확인\n",
    "    if importlib.util.find_spec(name) is None:\n",
    "        print(f\"[install] {pkg_name} 라이브러리를 설치 중입니다... (import name: {name})\")\n",
    "        try:\n",
    "            # -q 옵션을 추가하여 설치 과정을 간결하게 유지할 수 있습니다.\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg_name])\n",
    "            print(f\"[success] {pkg_name} 설치 완료.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"[error] {pkg_name} 설치 실패: {e}\")\n",
    "    else:\n",
    "        print(f\"[ok] {pkg_name} 이미 설치되어 있습니다.\")\n",
    "\n",
    "# 설치가 필요한 패키지 리스트 (패키지명, 임포트명)\n",
    "# 임포트명이 패키지명과 다른 경우 튜플로 지정합니다.\n",
    "packages = [\n",
    "    (\"torch\", \"torch\"),\n",
    "    (\"torchvision\", \"torchvision\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"onnx\", \"onnx\"),\n",
    "]\n",
    "\n",
    "# 루프를 돌며 확인 및 설치\n",
    "for pkg, imp in packages:\n",
    "    ensure_package(pkg, imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de63a21-4346-4a75-82da-7ae6b7775699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # path/환경 확인\n",
    "import random  # seed 고정\n",
    "import time  # epoch 시간 측정\n",
    "import numpy as np  # 수치 계산\n",
    "import torch  # PyTorch 본체\n",
    "import torch.nn as nn  # 모델 레이어\n",
    "import torch.nn.functional as F  # softmax 등 함수\n",
    "from torch.utils.data import DataLoader  # 데이터 로더\n",
    "import torchvision  # vision dataset/util\n",
    "import torchvision.transforms as T  # transform\n",
    "import torchvision.models as models  # resnet18\n",
    "import matplotlib.pyplot as plt  # 시각화\n",
    "\n",
    "print('torch:', torch.__version__)  # torch 버전 출력\n",
    "print('torchvision:', torchvision.__version__)  # torchvision 버전 출력\n",
    "print('cuda available:', torch.cuda.is_available())  # GPU 사용 가능 여부\n",
    "if torch.cuda.is_available():\n",
    "    print('gpu:', torch.cuda.get_device_name(0))  # GPU 이름 출력\n",
    "\n",
    "try:\n",
    "    get_ipython().system('nvidia-smi -L')  # GPU 목록 확인(가능한 경우)\n",
    "except Exception as e:\n",
    "    print('nvidia-smi not available:', e)  # nvidia-smi가 없는 환경이면 무시\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)  # python random seed\n",
    "    np.random.seed(seed)  # numpy seed\n",
    "    torch.manual_seed(seed)  # torch CPU seed\n",
    "    torch.cuda.manual_seed_all(seed)  # torch GPU seed\n",
    "    torch.backends.cudnn.deterministic = False  # 성능 우선(완전 재현성 X)\n",
    "    torch.backends.cudnn.benchmark = True  # 입력 크기 고정이면 속도 향상\n",
    "\n",
    "seed_everything(42)  # seed 고정(실험 재현성)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 실행 디바이스 선택\n",
    "device  # 디바이스 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a029c-bc06-44cf-af29-bb71126ea47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "## 1) Dataset: CIFAR-10 로드 + 입력 크기 확인\n",
    "- **목적:** 학습/평가에 사용할 데이터셋을 준비합니다.\n",
    "- **관찰 포인트**\n",
    "    - CNN 입력은 **(C,H,W)** 텐서이며, CIFAR-10은 **32×32** 입니다.\n",
    "    - augmentation(RandomCrop/Flip)을 적용합니다.\n",
    "    - CIFAR-10 데이터셋 구성\n",
    "       - Number of Classes: 10 (e.g., airplane, dog, cat, frog, etc.)\n",
    "       - Image Distribution: The dataset is class-balanced, with 6,000 images per class (5,000 for training and 1,000 for testing).\n",
    "       - Image Format: All images are 32x32 pixel color images (3 RGB channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e5a8a-1667-4d15-a102-58e5f8907292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10에서 널리 쓰는 normalize 값\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)  # 채널별 평균(R,G,B)\n",
    "CIFAR10_STD  = (0.2023, 0.1994, 0.2010)  # 채널별 표준편차(R,G,B)\n",
    "\n",
    "train_tfms = T.Compose([  # train transform(augmentation 포함)\n",
    "    T.RandomCrop(32, padding=4),  # 32x32를 padding 후 random crop\n",
    "    T.RandomHorizontalFlip(),  # 좌우 반전\n",
    "    T.ToTensor(),  # PIL -> torch tensor (C,H,W), 0~1\n",
    "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD),  # 정규화, -2.5~2.5\n",
    "])\n",
    "\n",
    "test_tfms = T.Compose([  # test transform(augmentation 없음)\n",
    "    T.ToTensor(),  # 텐서 변환\n",
    "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD),  # 정규화\n",
    "])\n",
    "\n",
    "data_root = './data'  # 데이터 저장 경로\n",
    "train_set = torchvision.datasets.CIFAR10(root=data_root, train=True, downloads=True, transform=train_tfms)\n",
    "test_set = torchvision.datasets.CIFAR10(root=data_root, train=False, downloads=True, transform=test_tfms)\n",
    "\n",
    "class_names = train_set.classes  # 클래스 이름 목록\n",
    "num_classes = len(class_names)  # 클래스 개수(10)\n",
    "print('classes:', class_names)  # 클래스 출력\n",
    "\n",
    "# 이미지 사이즈 출력\n",
    "x0, y0 = train_set[0]  # 한 샘플 로드(이미 transform 적용된 텐서)\n",
    "print('Sample image tensor shape (C,H,W):', tuple(x0.shape))  # (3,32,32)\n",
    "\n",
    "batch_size = 256  # 배치 크기\n",
    "num_workers = min(8, os.cpu_count() or 2)  # dataloader worker 수(환경에 맞게)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)  # test loader\n",
    "\n",
    "print('Total batch size (train: %d, test: %d)' % (len(train_loader), len(test_loader)))  # 배치 개수 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e1ff29-5984-48ec-8fe4-5bd17ea756a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    mean = torch.tensor(CIFAR10_MEAN).view(1,3,1,1)\n",
    "    std = torch.tensor(CIFAR10_STD).view(1,3,1,1)\n",
    "    return x * std + mean\n",
    "\n",
    "images, label = next(iter(train_loader))\n",
    "images_dn = denrom(images[:16]).clamp(0,1)\n",
    "\n",
    "grid = torchvision.utils.make_grid(images_dn, nrow=8)  # 그리드로 묶기(C,H,W)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.imshow(grid.permute(1,2,0))  # CHW -> HWC 로 변환 후 표시\n",
    "plt.axis('off')\n",
    "plt.title('CIFAR-10 samples (denormalized)')\n",
    "plt.show()\n",
    "\n",
    "print('labels:', [class_names[int(x)] for x in labels[:16]])  # 라벨 이름 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f77e2-cd4e-4775-8a44-020e61107ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet18_for_cifar10(num_classes: int =10):\n",
    "    model = models.resnet18(weight=None)\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"=== PyTorch model structure (Before) ===\")  # 모델 구조 출력\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "    print(model)  # 구조 출력\n",
    "    \n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "model = build_resnet18_for_cifar10(num_classes).to(device)\n",
    "    \n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"=== PyTorch model structure (After) ===\")  # 모델 구조 출력\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "print(model)  # 구조 출력\n",
    "\n",
    "num_params = sum(p.numel()) for p in model.parameters())\n",
    "print(f'params: {num_params:,}')  # 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f47c6a-ad8b-453b-875c-9df42bfaf640",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "## 3) 학습 유틸리티\n",
    "- **목적:** 학습/평가 루프를 재사용 가능하게 만들어 실험을 단순화합니다.\n",
    "- **관찰 포인트**\n",
    "  - `model.train()` vs `model.eval()` 차이\n",
    "  - AMP(Automatic Mixed Precision) 사용\n",
    "     - 계산이 복잡한 곳은 FP32를 쓰고, 단순한 곳은 FP16을 섞어서 사용\n",
    "     - GradScaler의 역할: FP16을 쓰면 기울기(Gradient) 값이 너무 작아져서 사라질 위험이 있음 (언더플로우)\n",
    "        - Scaling: 손실(Loss) 값에 아주 큰 값을 곱해 기울기를 크게 키움\n",
    "        - Backprop: 커진 상태로 역전파를 수행하여 값이 사라지지 않게 보호\n",
    "        - Unscaling: 업데이트 직전에 다시 원래 비율로 줄여서 가중치에 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35788f-5f1f-4302-9e18-84ef10e9861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass  # 설정을 깔끔하게 묶기 위한 dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    base_epochs_if_new: int = 20  # 처음 실험 시 epoch 수\n",
    "    extra_epochs_if_resume: int = 10  # 체크포인트 존재 시 추가 실험 epoch 수\n",
    "    lr: float = 0.1  # learning rate\n",
    "    weight_decay: float = 5e-4  # L2 정규화\n",
    "    momentum: float = 0.9  # SGD momentum\n",
    "    label_smoothing: float = 0.0  # 필요 시 label smoothing, 예) [0, 1, 0] ->  [0.05, 0.9, 0.05]\n",
    "\n",
    "cfg = TrainConfig()\n",
    "\n",
    "def accuracy_top1(logits, targets):\n",
    "    preds = logits.argmax(dim=1) # 가장 큰 logit의 클래스 선택, logits = [Batch, Classes], preds = [Batch]\n",
    "    return (preds==targets).float().mean().item()\n",
    "\n",
    "scaler = torch.amp.GradScaler(enable=torch.cuda.is_available())\n",
    "print (scaler)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0.0, 0.0\n",
    "    n=0\n",
    "    t0= time.time()\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images = imgaes.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=torch.cuda.is_available()):  # AMP autocast\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "            \n",
    "        \"\"\"\n",
    "        일반 학습\n",
    "        optimizer.zero_grad()\n",
    "         ...\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "       \n",
    "        AMP학습 (Mixed Precision)\n",
    "        optimizer.zero_grad()\n",
    "        ...\n",
    "        scaler.scale(loss).backward() # gradient를 스케일링 \n",
    "        scaler.step(optimizer) # 스케일링 해제 후 optimizer.step() 호출 \n",
    "        scaler.update() # 다음 step을 위한 scale 값 업데이트 \n",
    "        \"\"\"\n",
    "        \n",
    "        bs = images.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc += accuracy_top1(logits.detach(), labels) * bs\n",
    "        n += bs\n",
    "    dt = time.time() - t0  # epoch 수행 시간\n",
    "    return total_loss / n, total_acc / n, dt  # 평균 loss/acc/시간\n",
    "        \n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_acc = 0.0, 0.0  # 누적\n",
    "    n = 0  # 샘플 수\n",
    "    for images, labels in loader :\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        bs = images.size(0)  # batch size\n",
    "        total_loss += loss.item() * bs  # 누적\n",
    "        total_acc  += accuracy_top1(logits, labels) * bs  # 누적\n",
    "        n += bs  # 누적\n",
    "    return total_loss / n, total_acc / n  # 평균 loss/acc\n",
    "\n",
    "def plot_history(hist):\n",
    "    epochs = np.arange(1, len(hist['train_loss'])+1)  # epoch index\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(epochs, hist['train_loss'], label='train_loss')  # train loss\n",
    "    plt.plot(epochs, hist['val_loss'], label='val_loss')  # val loss\n",
    "    plt.xlabel('epoch'); plt.ylabel('loss'); plt.legend(); plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(epochs, hist['train_acc'], label='train_acc')  # train acc\n",
    "    plt.plot(epochs, hist['val_acc'], label='val_acc')  # val acc\n",
    "    plt.xlabel('epoch'); plt.ylabel('acc'); plt.legend(); plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50caa9-92ac-40ff-9e3d-291b6aecba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "## 4) ResNet18 학습\n",
    "- **목적:** CIFAR-10에서 ResNet18을 학습하고, 가장 좋은 성능의 모델을 저장합니다.\n",
    "- **관찰 포인트**\n",
    "    - `resnet18_cifar10.pth`가 있으면 **그 모델을 로드**하고 **10 epoch만 추가 학습**합니다.\n",
    "    - 파일이 없으면 **20 epoch 학습**합니다.\n",
    "    - 체크포인트로 실험을 이어갈 수 있다는 점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b240b67-d7d2-425d-9525-0afed0c3c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=cfg.label_smoothing)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr, momentum=cfg.momentum, weight_decay=cfg.weight_decay)\n",
    "\n",
    "ckpt_path = 'resnet18_cifar10.pth'  # best checkpoint 경로\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}  # 기록용 dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f14fc1-029e-4268-bf4e-23b0ca8ee273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009aa07-f6d3-4078-81f9-55cdb1739565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c55bc6-702a-49f3-8703-ac504b865f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24b5b0-c04b-4db2-9a99-0fe332b7c69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
