{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084b9e7-4418-4181-ac49-2d2254649913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet18_for_cifar10(num_classes: int = 10):\n",
    "    model = models.resnet18(weights=None)  # ImageNet pretrained 없이 ResNet18 생성 (from scratch)\n",
    "\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)  # CIFAR용 stem\n",
    "    model.maxpool = nn.Identity()  # maxpool 제거\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)  # 최종 분류기 출력=10\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba79296-5d2f-408b-bf16-bd1651f93991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" AMP와 AMP용 scalerdls GradScaler를 사용 \"\"\"\n",
    "\n",
    "scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())  \n",
    "# AMP용 scaler, 학습 속도를 높이고 메모리 사용량을 줄임\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()  # train mode(dropout/bn 동작 변경)\n",
    "    total_loss, total_acc = 0.0, 0.0  # 누적 loss/acc\n",
    "    n = 0  # 샘플 수 누적\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images = images.to(device, non_blocking=True)  # 입력을 GPU로 이동 (Asynchronous transfer)\n",
    "        labels = labels.to(device, non_blocking=True)  # 라벨을 GPU로 이동 (Asynchronous transfer)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)  # gradient 초기화\n",
    "\n",
    "        #AMP(Automatic Mixed Precision), 계산이 복잡한 곳은 FP32를 쓰고, 단순한 곳은 FP16을 섞어서 사용\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=torch.cuda.is_available()):  # AMP autocast\n",
    "            logits = model(images)  # forward\n",
    "            loss = criterion(logits, labels)  # loss 계산\n",
    "        \n",
    "        scaler.scale(loss).backward()  # scaled backward, 단순 loss.backward()와 다른점 유의\n",
    "        scaler.step(optimizer)  # optimizer step, scaler 안쓸때는 optimizer.step()\n",
    "        scaler.update()  # scaler 업데이트, scaler 안쓸때는 사용 안하던 코드인듯.\n",
    "\n",
    "        bs = images.size(0)  # batch size\n",
    "        total_loss += loss.item() * bs  # batch loss 누적\n",
    "        total_acc  += accuracy_top1(logits.detach(), labels) * bs  # logits값만 복사, batch acc 누적\n",
    "        n += bs  # 샘플 수 누적\n",
    "    \n",
    "    return total_loss / n, total_acc / n, dt  # 평균 loss/acc/시간\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcce29c-e4dc-4280-b86b-874682882ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()   # Autograd off, 함수 내부에서 기울기 계산 멈춤\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()  # eval mode, i.e., Dropout 비활성화, BN Running Stats 고정\n",
    "    total_loss, total_acc = 0.0, 0.0  # 누적\n",
    "    n = 0  # 샘플 수\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device, non_blocking=True)  # GPU 이동\n",
    "        labels = labels.to(device, non_blocking=True)  # GPU 이동\n",
    "        logits = model(images)  # forward\n",
    "        loss = criterion(logits, labels)  # loss, (lo, la) 순서 기억하자.\n",
    "        bs = images.size(0)  # batch size\n",
    "        total_loss += loss.item() * bs  # 누적\n",
    "        total_acc  += accuracy_top1(logits, labels) * bs  # 누적\n",
    "        n += bs  # 누적\n",
    "    return total_loss / n, total_acc / n  # 평균 loss/acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9c51f-81fb-4196-a0d7-bea1f8de2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 체크포인트로 실험을 이어가는 코드 봐두기 \"\"\"\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=cfg.label_smoothing)  # 분류 loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr, momentum=cfg.momentum, weight_decay=cfg.weight_decay)  # Mini-Batch SGD optimizer with Momentum\n",
    "\n",
    "ckpt_path = 'resnet18_cifar10.pth'  # best checkpoint 경로\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}  # 기록용 dict\n",
    "\n",
    "start_epoch = 0  # resume 시작 epoch\n",
    "best_acc = -1.0  # best val acc\n",
    "\n",
    "if os.path.exists(ckpt_path):  # 체크포인트가 있으면 resume\n",
    "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=True)  # checkpoint 로드\n",
    "    model.load_state_dict(ckpt['model'])  # 모델 가중치 로드\n",
    "    start_epoch = int(ckpt.get('epoch', 0))  # 저장된 epoch\n",
    "    best_acc = float(ckpt.get('val_acc', -1.0))  # 저장된 best acc\n",
    "    epochs_to_run = cfg.extra_epochs_if_resume  # 추가 실험 epoch = 10\n",
    "else:  # 체크포인트가 없으면 처음부터\n",
    "    epochs_to_run = cfg.base_epochs_if_new  # 신규 실험 epoch = 20\n",
    "\n",
    "# 학습률을 T_max에 맞춰 코사인 곡선 형태로 변화\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs_to_run)  \n",
    "# 이번 실험 구간에 대해 cosine schedule\n",
    "\n",
    "for e in range(1, epochs_to_run+1):\n",
    "    epoch = start_epoch + e  # 실제 epoch 번호(누적)\n",
    "    lr_now = optimizer.param_groups[0]['lr']  # 현재 lr, [ { 'params': [...], 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, ... } ]\n",
    "    tr_loss, tr_acc, dt = train_one_epoch(model, train_loader, optimizer, criterion)  # 1 epoch train\n",
    "    va_loss, va_acc = evaluate(model, test_loader, criterion)  # validation\n",
    "    scheduler.step()  # lr 스케줄 업데이트\n",
    "\n",
    "    history['train_loss'].append(tr_loss)  # 기록\n",
    "    history['train_acc'].append(tr_acc)  # 기록\n",
    "    history['val_loss'].append(va_loss)  # 기록\n",
    "    history['val_acc'].append(va_acc)  # 기록\n",
    "    history['lr'].append(lr_now)  # 기록\n",
    "    \n",
    "    if va_acc > best_acc:  # best 갱신 시 저장\n",
    "        best_acc = va_acc  # best 업데이트\n",
    "        torch.save({'model': model.state_dict(), 'epoch': epoch, 'val_acc': va_acc, 'config': cfg.__dict__}, ckpt_path)  # 체크포인트 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333381ac-421f-46e9-8d8c-e2603620fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 추론(Inference)\n",
    "    - 학습된 모델이 실제로 어떤 클래스로 예측하는지 확인\n",
    "    - softmax 확률과 confidence(최대 확률) 부분 잘 보기\n",
    "\"\"\"\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=device, weights_only=True)  # best checkpoint 로드\n",
    "model.load_state_dict(ckpt['model'])  # 최신 모델 가중치 적용\n",
    "model.eval()  # eval 모드, i.e., Dropout 비활성화, BN Running Stats 고정\n",
    "\n",
    "@torch.no_grad()  # 자동 미분(Autograd) 기능 비활성화\n",
    "def predict_batch(model, images):\n",
    "    logits = model(images)  # raw logits\n",
    "    probs = F.softmax(logits, dim=1)  # 확률로 변환, dim=0 은 batch 차원\n",
    "    conf, pred = probs.max(dim=1)  # 최대 확률(conf)과 클래스(pred)\n",
    "    return pred, conf, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ad103-6b20-4aa1-ba58-5e35d1e345ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" confusion matrix \n",
    "    그냥 preds, labels, images 를 cpu로 보내는것 정도만 봐도 될듯?\n",
    "\"\"\"\n",
    "@torch.no_grad()\n",
    "def collect_predictions(model, loader):\n",
    "    model.eval()  # eval 모드\n",
    "    all_preds, all_labels, all_images = [], [], []  # 누적 리스트\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)  # GPU 이동\n",
    "        labels = labels.to(device)  # GPU 이동\n",
    "        preds, conf, _ = predict_batch(model, images)  # 예측\n",
    "        all_preds.append(preds.cpu())  # CPU로 모아두기\n",
    "        all_labels.append(labels.cpu())  # CPU로 모아두기\n",
    "        all_images.append(images.cpu())  # 이미지도 저장(오분류 시각화용)\n",
    "    return torch.cat(all_images), torch.cat(all_preds), torch.cat(all_labels)  # 전체 텐서로 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acecf5a6-180b-4ede-8069-c9220aa73a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    per_class_acc 매트릭스 연산 정도만 체크해도?\n",
    "\"\"\"\n",
    "def confusion_and_perclass(preds, labels, num_classes):\n",
    "    cm = torch.zeros((num_classes, num_classes), dtype=torch.int64)  # confusion matrix 초기화\n",
    "    for t, p in zip(labels, preds):\n",
    "        cm[int(t), int(p)] += 1  # GT=t, Pred=p 카운트 증가\n",
    "    per_class_acc = cm.diagonal().float() / torch.clamp(cm.sum(dim=1).float(), min=1.0)  # 클래스별 정확도\n",
    "    return cm, per_class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654185e2-1a96-41da-933e-babf32b00d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca383c9b-92eb-456d-9ec6-ca63177e7205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8fccb-6526-46ea-af7d-ab3c7cf1a1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc35de-73fe-4d13-a42c-0cd061e0a113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7cc9ba-123c-4b24-ab89-20314d622e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
