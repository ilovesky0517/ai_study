{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb2539-c9a2-4205-a43a-15a4c74163b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = T.Compose([  # train transform(augmentation 포함)\n",
    "    T.RandomCrop(32, padding=4),  # 32x32를 padding 후 random crop\n",
    "    T.RandomHorizontalFlip(),  # 좌우 반전\n",
    "    T.ToTensor(),  # PIL -> torch tensor (C,H,W), 0~1\n",
    "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD),  # 정규화, -2.5~2.5\n",
    "])\n",
    "\n",
    "test_tfms = T.Compose([  # test transform(augmentation 없음)\n",
    "    T.ToTensor(),  # 텐서 변환\n",
    "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD),  # 정규화\n",
    "])\n",
    "\n",
    "data_root = './data'  # 데이터 저장 경로\n",
    "train_set = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=train_tfms)  # train set\n",
    "test_set  = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=test_tfms)  # test set\n",
    "\n",
    "class_names = train_set.classes  # 클래스 이름 목록, 이런식으로 바로 접근 가능한 경우도 있으니 체크는 해둘것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c9834-1ab8-4161-ac45-8257da10b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10에서 널리 쓰는 normalize 값\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)  # 채널별 평균(R,G,B)\n",
    "CIFAR10_STD  = (0.2023, 0.1994, 0.2010)  # 채널별 표준편차(R,G,B)\n",
    "\n",
    "def denorm(x): # -2.5~2.5\n",
    "    mean = torch.tensor(CIFAR10_MEAN).view(1,3,1,1)  # (1,3,1,1) 형태로 broadcast\n",
    "    std  = torch.tensor(CIFAR10_STD).view(1,3,1,1)  # (1,3,1,1) 형태로 broadcast\n",
    "    return x * std + mean  # 정규화 역변환, 0~1\n",
    "    # 이렇게 하면 shape이 (batch_size, 3, height, width)와 브로드캐스팅이 맞는단다.\n",
    "    # 즉, 각 채널별 평균값이 배치 전체와 모든 픽셀 위치에 자동으로 확장된다고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c3dfb-062e-4d77-bbd5-cc17cd4991da",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 파라미터 개수 체크\n",
    "num_params = sum(p.numel() for p in model.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b96203-ffff-4a6f-8b6b-8a54fe13b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습 모델 로드\n",
    "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)  # 가중치 포함 pretrained DETR-ResNet50 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc3253-9f94-440d-8fa2-a835b4c7a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 큰 logit의 클래스 선택, \n",
    "def accuracy_top1(logits, targets):\n",
    "    preds = logits.argmax(dim=1)  # logits = [B, C], preds = [B], dim=1이유는 dim=0은 batch 차원이라서\n",
    "    return (preds == targets).float().mean().item()  # top-1 accuracy, scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594de1d6-05a2-4035-b09b-53e239163866",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad(set_to_none=True)  # gradient 초기화\n",
    "# zero_grade는 모든 파라미터의 gradient를 초기화 해주는 역할\n",
    "# 다음 backward 시점에 새 텐서를 할당하게 됨. 불필요한 0 초기화 연산이 사라짐.\n",
    "# grad=0일 때는 gradient가 항상 존재하지만 값이 0.\n",
    "# grad=None일 때는 gradient가 아직 계산되지 않은 상태로 취급됩니다.\n",
    "# backward가 호출되면 새 gradient 텐서가 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5ef9d-bb42-4721-9cac-99b2aa7495db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 모델 안에서 특정 이름으로 지정된 모듈 찾아 반환 \"\"\"\n",
    "def get_module_by_name(model: nn.Module, name: str) -> nn.Module:\n",
    "    cur = model  # 시작 모듈\n",
    "    for part in name.split('.'):  # 점(.) 기준으로 순회\n",
    "        if part.isdigit():\n",
    "            cur = cur[int(part)]  # Sequential 인덱스 접근\n",
    "        else:\n",
    "            cur = getattr(cur, part)  # attribute 접근\n",
    "    return cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a36fee-8c91-460e-854d-e7eb31b5ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_activation(model, layer_name, x_single):\n",
    "    layer = get_module_by_name(model, layer_name)  # target layer\n",
    "    activ = {}  # 저장용 dict\n",
    "    def hook(m, i, o):  # callback function\n",
    "        activ['feat'] = o.detach().cpu()  # (B,C,H,W) 저장\n",
    "\n",
    "    h = layer.register_forward_hook(hook)  # target layer처리시 forward hook 등록 (hook 함수 실행)\n",
    "    model.eval()  # eval 모드\n",
    "    with torch.no_grad():\n",
    "        _ = model(x_single)  # forward 수행\n",
    "    h.remove()  # hook 제거\n",
    "    assert 'feat' in activ, f\"Hook failed for layer {layer_name}\"  # 방어 코드\n",
    "    return activ['feat'][0]  # (C,H,W) 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65555f4e-44f5-4b34-b488-022ecc18bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topk_activation_grid(feat_chw, title, topk=16):\n",
    "    ch_scores = feat_chw.abs().mean(dim=(1,2))  # 채널별 평균 크기 점수\n",
    "    idx = torch.topk(ch_scores, k=min(topk, feat_chw.shape[0])).indices  # Top-K 채널 인덱스\n",
    "    maps = []  # (K,1,H,W)로 만들 리스트\n",
    "    for ci in idx:\n",
    "        m = feat_chw[int(ci)]  # (H,W)\n",
    "        m = (m - m.min()) / (m.max() - m.min() + 1e-6)  # 0~1 정규화\n",
    "        maps.append(m[None, None, ...])  # (1,1,H,W)\n",
    "    maps = torch.cat(maps, dim=0)  # (K,1,H,W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60a30d-c2fa-46d3-934d-04e05043d683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd5245-4885-4feb-a2cb-11109741bd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae5172-03e9-4a9d-8faa-83ddca954241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad1eb5-01ae-4020-967e-8a55249127c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
