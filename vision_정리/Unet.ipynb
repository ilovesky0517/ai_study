{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194228de-d6a4-4296-aeac-fb660e226057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **U-Net — 기본 구조부터 학습 및 시각화까지**\n",
    "\n",
    " **U-Net 기반 이미지 세그멘테이션** 실습을 목표로 합니다.  \n",
    "다운샘플(Encoder) → 업샘플(Decoder) + **Skip Connection** 구조가 **왜 분할(segmentation)에 강한지**를 직접 확인합니다.\n",
    "\n",
    "## 학습 목표\n",
    "- U-Net의 **Encoder/Decoder/Skip Connection** 흐름을 코드에서 찾을 수 있다.\n",
    "- 입력/출력 텐서 shape이 단계별로 어떻게 바뀌는지 설명할 수 있다.\n",
    "- 간단한 데이터셋으로 **학습 → 검증 → 예측 시각화**까지 한 번에 실행할 수 있다.\n",
    "> Segmentation은 “어디에 무엇이 있는가”를 픽셀 단위로 예측합니다.  \n",
    "> 그래서 U-Net은 **공간 정보(spatial detail)** 를 보존/복원하기 위한 구조적 장치를 적극적으로 사용합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2dfe7a-59e2-42f4-b6cb-601e74b2813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) U-Net 모델 구현\n",
    "\n",
    "- **목적:** U-Net의 표준 블록을 구현하고, Encoder/Decoder의 연결 구조를 코드로 확인합니다.\n",
    "- **관찰 포인트**\n",
    "  - `DoubleConv`(Conv–BN–ReLU 반복)이 feature 추출에 어떻게 쓰이는지\n",
    "  - Down path에서 **Pooling/Stride**로 해상도가 줄어드는 지점\n",
    "  - Up path에서 **Up-sampling(ConvTranspose2d 또는 bilinear)** 이 적용되는 지점\n",
    "  - Skip 연결 시 **concat 채널 수**가 어떻게 증가하는지(가장 흔한 shape mismatch 원인)\n",
    "\n",
    "> 구현을 따라가면서 각 단계의 feature map 크기(H×W)와 채널(C)을 메모해 두면 이해가 훨씬 빨라집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca762c-e373-4aae-984e-86bc86ddd62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) U-Net 모델 정의\n",
    "# =========================\n",
    "# 이 섹션의 목표:\n",
    "# - U-Net의 \"인코더(Down) → 보틀넥 → 디코더(Up) + Skip Connection\" 구조를\n",
    "#   PyTorch 코드로 직접 따라가며 이해합니다.\n",
    "#\n",
    "# 핵심 아이디어(한 줄):\n",
    "# - Down에서 공간 해상도(H,W)는 줄이고 채널(C)은 늘리면서 특징을 추출하고,\n",
    "#   Up에서 해상도를 복원하면서 Down 단계의 특징맵을 Skip으로 concat하여\n",
    "#   localization(위치 정보)을 되살립니다.\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"U-Net 기본 블록: (Conv → ReLU) × 2\n",
    "\n",
    "    - 첫 번째 Conv가 채널을 '중간 채널(mid_channels)'로 바꾸고,\n",
    "      두 번째 Conv가 '출력 채널(out_channels)'로 맞춥니다.\n",
    "    - 기본값(mid_channels=None)일 때는 mid_channels=out_channels로 두어,\n",
    "      (C_in → C_out → C_out) 형태가 됩니다.\n",
    "\n",
    "    입력/출력 텐서 형태:\n",
    "      - 입력:  (B, C_in, H, W)\n",
    "      - 출력:  (B, C_out, H, W)  # padding=1 이라 H,W 유지\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, mid_channels: int | None = None):\n",
    "        super().__init__()\n",
    "\n",
    "        # U-Net에서 업샘플 후 concat을 하면 채널이 2배가 되므로,\n",
    "        # bilinear 업샘플링을 쓸 때는 mid_channels=in_channels//2 처럼\n",
    "        # '중간 채널'을 줄여주는 방식이 흔히 사용됩니다.\n",
    "        if mid_channels is None:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            # 1) (C_in → C_mid)\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 2) (C_mid → C_out)\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb226f97-3fa2-40f3-b305-9aa4bd5e55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Down(nn.Module):\n",
    "    \"\"\"Downsampling 블록: MaxPool(2)로 해상도 1/2 → DoubleConv\n",
    "\n",
    "    입력/출력 텐서 형태:\n",
    "      - 입력:  (B, C_in,  H,  W)\n",
    "      - 출력:  (B, C_out, H/2, W/2)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 1) 해상도 축소\n",
    "        x = self.pool(x)           # (B, C_in, H/2, W/2)\n",
    "        # 2) 채널 확장 + 특징 추출\n",
    "        x = self.conv(x)           # (B, C_out, H/2, W/2)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4777a24-3039-4922-8462-9e9bb6c10b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "    \"\"\"Upsampling 블록: 업샘플링 → (Skip concat) → DoubleConv\n",
    "\n",
    "    구현 관점(중요):\n",
    "    - in_channels 는 concat 이후 채널 수를 의미합니다.\n",
    "      예) x1(디코더) 채널=512, x2(skip) 채널=512 → concat 채널=1024 → in_channels=1024\n",
    "\n",
    "    - bilinear=True:\n",
    "        1) 업샘플은 파라미터 없는 bilinear interpolation으로 수행\n",
    "        2) concat 후 DoubleConv에서 mid_channels를 in_channels//2 로 두어\n",
    "           채널을 자연스럽게 '절반'으로 줄이는 방식(원 논문/레퍼런스 구현과 동일 계열)\n",
    "\n",
    "    - bilinear=False:\n",
    "        ConvTranspose2d로 업샘플 자체를 학습(파라미터 증가)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, bilinear: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            # (B, C, H/2, W/2) → (B, C, H, W)\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "            # bilinear일 때는 업샘플 후 채널 수(C)가 그대로 유지됩니다.\n",
    "            # concat 결과(in_channels)를 DoubleConv로 처리하되,\n",
    "            # 첫 conv의 출력(mid_channels)을 in_channels//2로 두어 채널을 줄입니다.\n",
    "            self.conv = DoubleConv(in_channels, out_channels, mid_channels=in_channels // 2)\n",
    "        else:\n",
    "            # (B, C, H/2, W/2) → (B, C/2, H, W)  (deconv가 채널도 절반으로 줄여줌)\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        # x1: (B, C_dec, H/2, W/2)  / x2: (B, C_skip, H, W)\n",
    "\n",
    "        # 1) 업샘플링: 해상도를 skip과 맞추기\n",
    "        x1 = self.up(x1)  # bilinear: 채널 유지 / deconv: 채널이 절반으로 감소\n",
    "\n",
    "        # 2) (필요 시) 패딩으로 크기 정렬\n",
    "        #    - 홀수 크기 입력 등으로 인해 x1과 x2의 H/W가 1~2 픽셀 정도 다를 수 있습니다.\n",
    "        diff_y = x2.size(2) - x1.size(2)\n",
    "        diff_x = x2.size(3) - x1.size(3)\n",
    "        x1 = F.pad(x1, [diff_x // 2, diff_x - diff_x // 2,  # left, right\n",
    "                        diff_y // 2, diff_y - diff_y // 2]) # top, bottom\n",
    "\n",
    "        # 3) 채널 방향 concat (skip 연결)\n",
    "        #    cat dim=1 은 채널(C) 축\n",
    "        x = torch.cat([x2, x1], dim=1)  # (B, C_skip + C_up, H, W) == (B, in_channels, H, W)\n",
    "\n",
    "        # 4) conv 블록으로 특징 정제 + 채널 축소\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06aebd-f986-4542-a82b-10723e0a3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    \"\"\"마지막 1x1 conv: 채널을 클래스 수로 매핑\n",
    "\n",
    "    예)\n",
    "      - binary segmentation: n_classes=1 (logits 1채널)\n",
    "      - multi-class:         n_classes=K (logits K채널)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4665995-e6a1-4ddb-97b0-757d7df797e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net 전체 모델\n",
    "\n",
    "    전형적인 채널 구성 예:\n",
    "      1 → 64 → 128 → 256 → 512 → 1024 (down)\n",
    "      1024 → 512 → 256 → 128 → 64 (up)\n",
    "      숫자 외워야 할 듯.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels: int, n_classes: int, bilinear: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        # -------------------------\n",
    "        # Encoder (Contracting path)\n",
    "        # -------------------------\n",
    "        self.inc = DoubleConv(n_channels, 64)   # (B, n_channels, H, W) → (B, 64, H, W)\n",
    "        self.down1 = Down(64, 128)              # → (B, 128, H/2, W/2)\n",
    "        self.down2 = Down(128, 256)             # → (B, 256, H/4, W/4)\n",
    "        self.down3 = Down(256, 512)             # → (B, 512, H/8, W/8)\n",
    "\n",
    "        # bilinear 업샘플링이면 파라미터/연산을 줄이기 위해 bottleneck 채널을 1024 대신 512로 줄이는 경우가 많음\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)  # → (B, 1024/f, H/16, W/16)\n",
    "\n",
    "        # -------------------------\n",
    "        # Decoder (Expanding path)\n",
    "        # -------------------------\n",
    "        # Up 블록의 in_channels는 \"concat 후 채널\" 기준으로 설계되어야 합니다.\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)  # (skip=512)와 concat을 고려\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "\n",
    "        # -------------------------\n",
    "        # Output head\n",
    "        # -------------------------\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # -------------------------\n",
    "        # Encoder: skip을 위해 각 단계 출력 저장\n",
    "        # -------------------------\n",
    "        x1 = self.inc(x)       # (B, 64, H, W)\n",
    "        x2 = self.down1(x1)    # (B, 128, H/2, W/2)\n",
    "        x3 = self.down2(x2)    # (B, 256, H/4, W/4)\n",
    "        x4 = self.down3(x3)    # (B, 512, H/8, W/8)\n",
    "        x5 = self.down4(x4)    # (B, 1024/f, H/16, W/16)\n",
    "\n",
    "        # -------------------------\n",
    "        # Decoder: 업샘플 + skip concat\n",
    "        # -------------------------\n",
    "        x = self.up1(x5, x4)   # (B, 512/f, H/8, W/8)\n",
    "        x = self.up2(x, x3)    # (B, 256/f, H/4, W/4)\n",
    "        x = self.up3(x, x2)    # (B, 128/f, H/2, W/2)\n",
    "        x = self.up4(x, x1)    # (B, 64, H, W)\n",
    "\n",
    "        # -------------------------\n",
    "        # 최종 logits 출력\n",
    "        # -------------------------\n",
    "        logits = self.outc(x)  # (B, n_classes, H, W)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a31ee-4635-46fb-9663-7008e7ad6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    - Binary segmentation이면 보통 `BCEWithLogitsLoss`를 많이 사용(로짓 입력 주의)\n",
    "    - Multi-class segmentation이면 `CrossEntropyLoss`(타깃은 class index) 사용\n",
    "    - `sigmoid/softmax`를 **언제 적용해야 하는지**(loss와의 궁합)\n",
    "  \"\"\"\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.BCEWithLogitsLoss()  # Sigmoid + Binary Cross Entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# (옵션) 학습 스케줄러\n",
    "# 20 에포크(Epoch)마다 학습률을 변경, 기존 학습률에 0.5를 곱합\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04261e-5d09-4d8a-a46a-27f67e815595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c2e9c-66e7-403c-a8a4-e61464b3a88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
