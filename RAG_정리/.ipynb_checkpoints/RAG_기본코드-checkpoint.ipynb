{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aaebd4-4edf-4504-8016-159ba1749b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VectorStoreInex를 어떻게 선언하는지 숙지하기E ###\n",
    "\n",
    "city_names = ['Berlin', 'Shanghai', 'Los Angeles', 'Seoul', 'Saint Petersburg', \n",
    "              'Beijing', 'Rio de Janeiro', 'Mexico City', 'Budapest', 'Barcelona', \n",
    "              'Antananarivo', 'Suwon', 'Belize City']\n",
    "\n",
    "reader = WikipediaReader()\n",
    "documents = reader.load_data(city_names, auto_suggest=False)\n",
    "index = VectorStoreIndex.from_documents(documents) # 외워야 할 듯\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d6d7d-2ee3-4879-8dd3-d42f3d7a94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAG = Retrieval-Augmented Generation 임을 항상 기억하기 ###\n",
    "\n",
    "oai_client = OpenAI()\n",
    "\n",
    "class RAG_from_scratch:\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        # RAG에서 \"검색(Retrieval)\" 단계에 해당\n",
    "        results = query_engine.query(query)\n",
    "        return results\n",
    "\n",
    "    def generate_response(self, query: str, context_str: list) -> str:\n",
    "        # RAG에서 \"생성(Generation)\" 단계에 해당\n",
    "        completion = oai_client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0,\n",
    "            messages=\n",
    "            [\n",
    "                {\"role\": \"user\",\n",
    "                \"content\":\n",
    "                f\"We have provided context information below. \\n\"\n",
    "                f\"---------------------\\n\"\n",
    "                f\"{context_str}\"\n",
    "                f\"\\n---------------------\\n\"\n",
    "                f\"Given this information, please answer the question: {query}\"\n",
    "                    #{\"role\": \"user\", \"content\": ...}\n",
    "                    #{\"role\": \"system\": \"content\": ...} 형태\n",
    "                }\n",
    "            ]\n",
    "        ).choices[0].message.content \n",
    "            # API 호출 결과에서 첫 번째 응답(choices[0])을 가져온다.\n",
    "            # message.content는 모델이 생성한 실제 텍스트 답변        \n",
    "        return completion\n",
    "\n",
    "    def query(self, query: str) -> str: # 전체 파이프라인을 실행하는 메서드.\n",
    "        context_str = self.retrieve(query) # retrieve를 호출해 관련 문맥을 가져오고\n",
    "        completion = self.generate_response(query, context_str) # 최종 답변을 생성시킴\n",
    "        return completion\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa72697-9a20-4fc8-b58f-33b8de603ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "### 복사하긴 했지만 형태만 약간 다를뿐 위에 있는 generate_response와 거의 유사한 내용 ###\n",
    "\n",
    "def generate_answer(question):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54002bc1-de29-40eb-a58c-0b90dffe203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_domains = {}\n",
    "for item in dataset: # dataset을 순회하면서,\n",
    "    if 'domain' in item: # 각 item에 'domain' 키가 있으면 그 값을 기준으로\n",
    "        domain_value = item['domain']\n",
    "        if domain_value not in unique_domains: # 고유한 도메인별 첫 번째 item만 저장하는 로직\n",
    "            unique_domains[domain_value] = item\n",
    "\n",
    "# 이런식으로 사용할수도 있음. 결국은 키값을 기준으로 샘플 만들어 내는거\n",
    "unique_dynamism = {}\n",
    "for item in dataset:\n",
    "    if 'static_or_dynamic' in item:\n",
    "        question_type = item['static_or_dynamic']\n",
    "        if question_type not in unique_dynamism:\n",
    "            unique_dynamism[question_type] = item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e8de1-52a8-4c12-9bce-6c64af95dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []\n",
    "\n",
    "for html_text in example_data['search_results']:\n",
    "    soup = BeautifulSoup(html_text[\"page_result\"], features=\"lxml\")\n",
    "    text = soup.get_text(\" \", strip=True)\n",
    "    # HTML 태그를 제거하고 순수 텍스트만 추출\n",
    "    if not text:\n",
    "        all_chunks.append(\"\")\n",
    "    else:\n",
    "        _, offsets = text_to_sentences_and_offsets(text)\n",
    "        # 텍스트를 문장 단위로 나누고, 각 문장의 시작과 끝 위치(offset)를 계산\n",
    "        # offsets는 문장별로 (start, end) 인덱스를 담고 있는 리스트\n",
    "\n",
    "        chunks = []\n",
    "\n",
    "        for start, end in offsets:\n",
    "            chunk = text[start:end][:4000] # 문자열이 너무 길 경우 최대 4000자까지만 유지\n",
    "            all_chunks.append(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee19f4e-6d8e-49c4-8fc4-1798e4a08ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddbc72d-a39c-4a2d-91a7-fb44ee0c49da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e35ad-10e2-421a-bde0-2670c1fa735b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
