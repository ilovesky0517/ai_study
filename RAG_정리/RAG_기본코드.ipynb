{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aaebd4-4edf-4504-8016-159ba1749b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VectorStoreInex를 어떻게 선언하는지 숙지하기E ###\n",
    "\n",
    "city_names = ['Berlin', 'Shanghai', 'Los Angeles', 'Seoul', 'Saint Petersburg', \n",
    "              'Beijing', 'Rio de Janeiro', 'Mexico City', 'Budapest', 'Barcelona', \n",
    "              'Antananarivo', 'Suwon', 'Belize City']\n",
    "\n",
    "reader = WikipediaReader()\n",
    "documents = reader.load_data(city_names, auto_suggest=False)\n",
    "index = VectorStoreIndex.from_documents(documents) # 외워야 할 듯\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26ee79-f776-4c7c-9bbb-c423a97953da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM에 보내는 프롬프트는 기본적으로 요런 구조 \n",
    "    여기에 f\" ... \" 이런걸 추가해서 보낸다.\n",
    "###\n",
    "messages = [\n",
    "        { \"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        { \"role\": \"user\",   \"content\": question, },\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa72697-9a20-4fc8-b58f-33b8de603ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "### 복사하긴 했지만 형태만 약간 다를뿐 위에 있는 generate_response와 거의 유사한 내용 ###\n",
    "\n",
    "def generate_answer(question):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54002bc1-de29-40eb-a58c-0b90dffe203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_domains = {}\n",
    "for item in dataset: # dataset을 순회하면서,\n",
    "    if 'domain' in item: # 각 item에 'domain' 키가 있으면 그 값을 기준으로\n",
    "        domain_value = item['domain']\n",
    "        if domain_value not in unique_domains: # 고유한 도메인별 첫 번째 item만 저장하는 로직\n",
    "            unique_domains[domain_value] = item\n",
    "\n",
    "# 이런식으로 사용할수도 있음. 결국은 키값을 기준으로 샘플 만들어 내는거\n",
    "unique_dynamism = {}\n",
    "for item in dataset:\n",
    "    if 'static_or_dynamic' in item:\n",
    "        question_type = item['static_or_dynamic']\n",
    "        if question_type not in unique_dynamism:\n",
    "            unique_dynamism[question_type] = item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e8de1-52a8-4c12-9bce-6c64af95dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []\n",
    "\n",
    "for html_text in example_data['search_results']:\n",
    "    soup = BeautifulSoup(html_text[\"page_result\"], features=\"lxml\")\n",
    "    text = soup.get_text(\" \", strip=True)\n",
    "    # HTML 태그를 제거하고 순수 텍스트만 추출\n",
    "    if not text:\n",
    "        all_chunks.append(\"\")\n",
    "    else:\n",
    "        _, offsets = text_to_sentences_and_offsets(text)\n",
    "        # 텍스트를 문장 단위로 나누고, 각 문장의 시작과 끝 위치(offset)를 계산\n",
    "        # offsets는 문장별로 (start, end) 인덱스를 담고 있는 리스트\n",
    "\n",
    "        chunks = []\n",
    "\n",
    "        for start, end in offsets:\n",
    "            chunk = text[start:end][:4000] # 문자열이 너무 길 경우 최대 4000자까지만 유지\n",
    "            all_chunks.append(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee19f4e-6d8e-49c4-8fc4-1798e4a08ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddbc72d-a39c-4a2d-91a7-fb44ee0c49da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e35ad-10e2-421a-bde0-2670c1fa735b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
