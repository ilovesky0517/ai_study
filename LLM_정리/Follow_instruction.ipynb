{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eefb9b-5218-4e5b-8746-0c4eeb36aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    \"\"\"\n",
    "    Alpaca 스타일의 프롬프트 템플릿을 적용하는 함수.\n",
    "    모델에게 역할을 부여하고 입력 형식을 통일합니다.\n",
    "    \"\"\"\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # 추가적인 입력 정보(Context 등)가 있는 경우 추가\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f207380-cd99-4c0d-9f06-1baa1be0b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    지시사항(Instruction) 데이터셋을 처리하는 PyTorch Dataset 클래스.\n",
    "    입력 데이터(지시+입력)와 정답 데이터(응답)를 하나의 텍스트로 합쳐서 토큰화합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # 텍스트 데이터 미리 토큰화 (Pre-tokenize)\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            # 포맷팅 함수를 이용해 \"지시사항 + 입력\" 텍스트 생성\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            # 정답(Response) 텍스트 생성\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            \n",
    "            # 모델은 이 전체 텍스트(질문+답변)를 보고 다음 토큰을 예측하도록 학습됨\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de73f3-2893-41e3-9a47-94b612d70426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn( batch,\n",
    "    pad_token_id=50256, ignore_index=-100, allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    데이터 로더에서 배치를 만들 때 사용하는 커스텀 함수.\n",
    "    가변 길이의 시퀀스를 배치의 최대 길이에 맞춰 패딩(padding)하고, \n",
    "    정답(target) 데이터에서 패딩 부분은 손실(loss) 계산에서 제외하도록 처리합니다.\n",
    "    \"\"\"\n",
    "    # 배치 내에서 가장 긴 시퀀스 길이 계산 (패딩을 위해 +1 여유)\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    \n",
    "    # 입력(inputs)과 정답(targets) 리스트 준비\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # 문장 끝 토큰 <|endoftext|> 추가\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        # 가장 긴 길이에 맞춰 패딩 추가\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        \n",
    "        # 입력은 마지막 토큰 제외 (0 ~ n-1)\n",
    "        inputs = torch.tensor(padded[:-1]) \n",
    "        # 정답은 첫 번째 토큰 제외 (1 ~ n) -> 다음 토큰 예측 문제이므로\n",
    "        targets = torch.tensor(padded[1:]) \n",
    "\n",
    "        # 중요: 패딩 부분 마스킹 처리\n",
    "        # 타겟에서 패딩 토큰인 부분은 ignore_index(-100)로 바꿔서 CrossEntropyLoss 계산 시 무시되게 함\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        \n",
    "        # 패딩이 시작되는 지점 이후의 모든 타겟 값을 -100으로 설정\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        # indices[1:] → 첫 번째 pad 위치를 제외한 나머지 pad 위치 인덱스 \n",
    "        # 위치의 targets 값을 ignore_index로 바꿉니다.\n",
    "        \n",
    "        # 선택적으로 최대 시퀀스 길이 제한 (메모리 관리 등 목적)\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    # 텐서로 변환 및 디바이스(GPU/CPU)로 이동\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80719f6f-c69e-40a1-8a7d-1fb62a8f586d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548fe87c-bafa-448a-8a76-43861f8f6af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf84cda-3338-434b-8ae4-cba6348f67e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a94f8-a1bf-4aac-889e-4e03bb3c5993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65fff3-7aec-475b-b5e4-b4ef92648176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8d23c-a1fa-47cc-b91c-5763c3ddb328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
