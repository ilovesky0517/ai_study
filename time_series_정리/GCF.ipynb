{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f559cc5-a720-44b4-bd90-a214b4a5b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform UserID and MovieID into sequential indices\n",
    "user_encoder = {user: idx for idx, user in enumerate(rating_df['userId'].unique())}\n",
    "movie_encoder = {movie: idx for idx, movie in enumerate(rating_df['movieId'].unique())}\n",
    "\n",
    "rating_df['userId'] = rating_df['userId'].map(user_encoder)\n",
    "rating_df['movieId'] = rating_df['movieId'].map(movie_encoder)\n",
    "\n",
    "num_users = len(user_encoder)\n",
    "num_movies = len(movie_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66737cd-3152-4faf-8435-24039914f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Edge for Graph\n",
    "# We generate edge between user and movie when user rates movie higher than (or equal to) 1\n",
    "# Adjacency matrix 대신 edge_index를 넣어서도 진행가능하다.\n",
    "def create_edge_index(df, rating_threshold=1.0):\n",
    "    src, dst = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['rating'] >= rating_threshold:\n",
    "            src.append(row['userId'])\n",
    "            # item indices after user indices\n",
    "            dst.append(row['movieId'] + num_users)\n",
    "    return torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "edge_index = create_edge_index(rating_df)\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d2624-c830-4759-8e50-ce4839b9f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices into train/val/test set (label for train/val/test set)\n",
    "train_indices, test_indices = train_test_split(range(edge_index.size(1)), test_size=0.2)\n",
    "# edge_index의 shape은 (2, num_edges), 따라서 edge_index.size(1) = num_edges (간선 개수)\n",
    "val_indices, test_indices = train_test_split(test_indices, test_size=0.5)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]\n",
    "# edge에서는 다른 분야와 다른게 index 형태로 접근하는 것을 체크해 두기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79df0df1-e938-424e-ab4c-37dcc33b87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGCFLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(input_dim, output_dim)\n",
    "        self.W2 = nn.Linear(input_dim, output_dim)\n",
    "            # self.dropout = nn.Dropout(dropout)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, edge_index, node_features, user_num, item_num):\n",
    "        '''\n",
    "        edge_index : 엣지 정보 (src, dst)의 집합.\n",
    "        node_features: node별 이전 layer에서 생성된 벡터 정보가 담긴 matrix (H^(l-1)) (|V| * d)\n",
    "        '''\n",
    "\n",
    "        src, dst = edge_index # src : user, dst : movie\n",
    "\n",
    "            # calculate node degree\n",
    "        deg = torch.zeros(node_features.size(0), device=node_features.device)\n",
    "            # calculate user degree\n",
    "        deg.index_add_(0, src, torch.ones_like(src, dtype=torch.float))\n",
    "            # calculate movie degree\n",
    "        deg.index_add_(0, dst, torch.ones_like(dst, dtype=torch.float))\n",
    "\n",
    "            # calculate 1/(root(deg(u)) * root(deg(i))) for all edge\n",
    "        norm = 1.0/torch.sqrt(deg[src]*deg[dst])\n",
    "\n",
    "        src_feat = node_features[src] # H_u\n",
    "        dst_feat = node_features[dst] # H_i\n",
    "\n",
    "            # edge_messages for user(src) = m_(u<-i)) 결과 저장.\n",
    "            # Hint: step1. self.W1(h_i) + self.W2(h_u * h_i) 계산\n",
    "            # Hint: step2. 최종 m_(u<-i)를 위해선 앞선 norm을 앞서 계산한 message에 곱하기\n",
    "        edge_messages_for_src = self.W1(dst_feat) + self.W2(dst_feat*src_feat)\n",
    "        edge_messages_for_src *= norm.unsqueeze(1)  # unsqueeze(1)는 shape 맞추기\n",
    "            #단순히 neighbor feature만 쓰지 않고, 두 노드의 상호작용을 함께 학습\n",
    "            #neighbor 정보 + interaction 정보 → 최종 edge 메시지\n",
    "            # W1에는 1개짜리, 상대방(src <->dst)이 들어가거 W2에는 2개 다 들어간다고 생각하자.(순서는 역시 상대방부터)\n",
    "\n",
    "            # edge_messages for movie(dst) = m_(i<-u)) 결과 저장.\n",
    "            # Hint: step1. self.W1(h_u) + self.W2(h_i * h_u) 계산\n",
    "            # Hint: step2. 최종 m_(i<-u)를 위해선 앞선 norm을 앞서 계산한 message에 곱하기\n",
    "        edge_messages_for_dst = self.W1(src_feat) + self.W2(src_feat*dst_feat)\n",
    "        edge_messages_for_dst *= norm.unsqueeze(1)\n",
    "\n",
    "            # aggregated_features = Combine()의 결과 저장.\n",
    "        aggregated_messages = torch.zeros_like(node_features)\n",
    "            # m_(u<-u) = self.W1(h_u) 계산해 더해주기\n",
    "        aggregated_messages.index_add(0, src, edge_messages_for_src)\n",
    "        aggregated_messages[:user_num] += self.W1(node_features[:user_num])\n",
    "\n",
    "            # m_(i<-i) = self.W1(h_i) 계산해 더해주기\n",
    "        aggregated_messages.index_add_(0, dst, edge_messages_for_dst)\n",
    "        aggregated_messages[user_num:] += self.W1(node_features[user_num:])\n",
    "        # []안의 인덱스를 잘 봐야 할 듯. src는 user 관련된거니까 0~user_num-1 까지 : [:user_num], dst는 그 뒤니까 user_num: 로 \n",
    "\n",
    "        aggregated_features = self.leaky_relu(aggregated_messages)\n",
    "\n",
    "        # engineering approach\n",
    "        # aggregated_features = self.dropout(aggregated_features)\n",
    "        return aggregated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2d769-4cc3-4087-a3cd-f2a09c7a0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: NGCF 모델 완성.\n",
    "\n",
    "class NGCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, layer_dims, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.node_embeddings = nn.Embedding(self.num_users+self.num_items,self.embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.node_embeddings.weight) # 일단 외워라...\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            NGCFLayer(input_dim=(embedding_dim if i == 0 else layer_dims[i - 1]),\n",
    "                      output_dim=layer_dims[i], dropout=dropout)\n",
    "            for i in range(len(layer_dims))\n",
    "        ])\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        node_features = self.node_embeddings.weight # (num_nodes, d₀),  d₀는 초기 임베딩 차원\n",
    "        layer_outputs = [node_features]\n",
    "        for layer in self.layers:\n",
    "            node_features = layer(edge_index, node_features,self.num_users, self.num_items)\n",
    "            layer_outputs.append(node_features)\n",
    "\n",
    "        # Hint: NGCF의 final feature(representation)은 layer 별 feature에 대한 concatenated vector\n",
    "        # Hint: 최종 final feature matrix에는 [feuture_vector for users + feature_vector for items]가 들어있음.\n",
    "\n",
    "        final_features = torch.concat(layer_outputs,dim=-1) # 레이어별 임베딩을 feature dimension 기준으로 이어붙임(concatenate)\n",
    "        user_features = final_features[:self.num_users] # self.num_users 를 기억해보자.\n",
    "        item_features = final_features[self.num_users:]\n",
    "        return user_features, item_features\n",
    "\n",
    "    def bpr_loss(self, user_emb, pos_item_emb, neg_item_emb, reg_weight=1e-4):\n",
    "        pos_scores = torch.sum(user_emb * pos_item_emb, dim=1)\n",
    "        neg_scores = torch.sum(user_emb * neg_item_emb, dim=1)\n",
    "        loss = -torch.mean(F.logsigmoid(pos_scores - neg_scores)) #평균을 취하고 음수 부호를 붙여서 최대화 문제를 최소화 문제로 변환\n",
    "        reg_loss = reg_weight * (user_emb.norm(2).pow(2) + pos_item_emb.norm(2).pow(2) \\ #각 임베딩의 L2 norm 제곱을 더함 → 파라미터 크기 제한\n",
    "                                 + neg_item_emb.norm(2).pow(2)) / user_emb.size(0) # 배치 크기 기준으로 평균화\n",
    "        return loss + reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11d834-9df9-447b-8bb8-b3c5facb14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 위 코드에서 layer_outputs와 final_features에 대한 보충 설명 예시\n",
    "    num_users = 3, num_items = 2 → num_nodes = 5\n",
    "        초기 임베딩 차원 d₀ = 4\n",
    "        레이어 1 출력 차원 d₁ = 8\n",
    "        레이어 2 출력 차원 d₂ = 8\n",
    "    layer_outputs:\n",
    "        H^(0): (5, 4)\n",
    "        H^(1): (5, 8)\n",
    "        H^(2): (5, 8)\n",
    "    final_features: (5, 4+8+8) = (5, 20)\n",
    "    user_features: (3, 20)\n",
    "    item_features: (2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd2edd-4859-4ccd-b57d-9453bae9878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(user_features, item_features, test_edge_index, k):\n",
    "    # user_features : (num_users, d)\n",
    "    # item_features : (num_items, d)\n",
    "    # test_edge_index: shape (2, E_test) (테스트 간선 집합)\n",
    "    user_pos_items = defaultdict(list) # 존재하지 않는 키를 호출하면 자동으로 빈 리스트([])를 생성해준다고...\n",
    "    E_test = test_edge_index.size(1) # test_edge_index가 (2, 1000)이면 E_test = 1000 \n",
    "                                    # → 테스트 데이터에 1000개의 사용자-아이템 상호작용이 있다는 뜻\n",
    "    for i in range(E_test):\n",
    "        u = test_edge_index[0, i].item() # 결과적으로 u는 사용자 ID (0 ~ num_users-1 범위).\n",
    "        it = test_edge_index[1, i].item() - num_users #  it는 아이템 ID (0 ~ num_items-1 범위).\n",
    "        user_pos_items[u].append(it) # 예: user_pos_items[3] = [10, 25, 47] \n",
    "                                # → 사용자 3은 아이템 10, 25, 47을 긍정적으로 상호작용한 기록이 있음.\n",
    "\n",
    "    recalls, precisions, ndcgs = [], [], []\n",
    "    for user, pos_items in user_pos_items.items(): \n",
    "        user_emb = user_features[user] # user_features[user]는 특정 사용자 user의 임베딩 벡터 (d,)를 가져옴\n",
    "        scores = torch.matmul(item_features, user_emb) # item_features는 (num_items, d), 결과는 (num_items,)\n",
    "        topk_scores, topk_indices = torch.topk(scores, k=k) # 용자에게 추천할 Top‑K 아이템 후보군을 뽑아냅\n",
    "        topk_indices = topk_indices.cpu().numpy().tolist() # 이후 조건문에서 리스트 연산을 쉽게 하기 위해 변환하는 과정\n",
    "\n",
    "        hits = 0\n",
    "        dcg = 0.0\n",
    "        idcg = 0.0\n",
    "        n_pos = len(pos_items)\n",
    "\n",
    "        for rank, item_idx in enumerate(topk_indices):\n",
    "            if item_idx in pos_items:\n",
    "                hits += 1\n",
    "                dcg += 1.0 / math.log2(rank + 2) # rank는 0부터 시작하므로 rank+2\n",
    "                    # 예: 1등(rank=0) → 1/log2(2) = 1.0 / 2등(rank=1) → 1/log2(3) ≈ 0.63\n",
    "        for rank in range(min(n_pos, k)):\n",
    "            idcg += 1.0 / math.log2(rank + 2)\n",
    "\n",
    "        recall_u = hits / n_pos\n",
    "        precision_u = hits / k\n",
    "        ndcg_u = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "        recalls.append(recall_u)\n",
    "        precisions.append(precision_u)\n",
    "        ndcgs.append(ndcg_u)\n",
    "\n",
    "    recall = np.mean(recalls)\n",
    "    precision = np.mean(precisions)\n",
    "    ndcg = np.mean(ndcgs)\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb5f74b-e33a-44a2-b3ae-d405b617890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_edge_index, val_edge_index, num_epochs, batch_size, device, k):\n",
    "    model.to(device)\n",
    "    train_edge_index = train_edge_index.to(device)\n",
    "    val_edge_index = val_edge_index.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = len(train_edge_index[0]) // batch_size\n",
    "\n",
    "        for _ in range(num_batches):\n",
    "            indices = torch.randint(0, train_edge_index.size(1), (batch_size,), device=device)\n",
    "                # low = 0, high = train_edge_index.size(1) → 간선 개수\n",
    "                # size = (batch_size,) → 배치 크기만큼 인덱스를 뽑음, device = device → CPU/GPU 위치 지정\n",
    "            user_indices = train_edge_index[0, indices] # 랜덤하게 선택된 간선들의 사용자 노드 인덱스 집합\n",
    "            pos_item_indices = train_edge_index[1, indices] - num_users \n",
    "                # 현재 배치에서 학습에 사용할 긍정 아이템 인덱스(0 ~ num_items-1 범위)\n",
    "            neg_item_indices = torch.randint(0, num_movies, (batch_size,), device=device)\n",
    "                # 아무 영화나 뽑아와서 '보지않은'영화로 간주하고 negative sample로 쓰자.\n",
    "                # 보지 않은 영화임을 보장할 수 없는데 단순 실습이라서 그런듯.\n",
    "\n",
    "            user_features, item_features = model(train_edge_index)\n",
    "            u_emb = user_features[user_indices]\n",
    "            pos_emb = item_features[pos_item_indices]\n",
    "            neg_emb = item_features[neg_item_indices]\n",
    "\n",
    "            loss = model.bpr_loss(u_emb, pos_emb, neg_emb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / num_batches:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                user_features, item_features = model(train_edge_index)\n",
    "                recall, precision, ndcg = evaluate(user_features.cpu(), item_features.cpu(), val_edge_index, k)\n",
    "                print(f\"[Validation] Epoch {epoch + 1}: Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}, NDCG@{k}: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c8938-896f-4fca-b6ad-a05160922a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, train_edge_index, test_edge_index, k, device):\n",
    "    model.eval()\n",
    "    train_edge_index = train_edge_index.to(device)\n",
    "    test_edge_index = test_edge_index.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        user_features, item_features = model(train_edge_index)\n",
    "\n",
    "    user_features = user_features.cpu()\n",
    "    item_features = item_features.cpu()\n",
    "\n",
    "    recall, precision, ndcg = evaluate(user_features, item_features, test_edge_index, k)\n",
    "    recall = round(recall, 4)\n",
    "    precision = round(precision, 4)\n",
    "    ndcg = round(ndcg, 4)\n",
    "\n",
    "    print(f\"Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}, NDCG@{k}: {ndcg:.4f}\")\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad347bd-87c3-420a-8d29-0161e7d2d08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d07fd-3403-4845-9af5-09845ce72294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea04a21-809a-4401-a70b-61603c284e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
