{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3aa25-a45d-492a-95ef-fe81ebc3245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Collaborative filtering\n",
    "\n",
    "df.userId = lbl_user.fit_transform(df.userId.values)\n",
    "    # userId 값이 [\"A\", \"B\", \"C\", \"A\"]라면:\n",
    "    # fit 단계에서 A→0, B→1, C→2로 매핑합니다.\n",
    "    # transform 단계에서 [\"A\", \"B\", \"C\", \"A\"] → [0, 1, 2, 0]으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc352b0-bc9e-4d92-8563-165cd1cfc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embedding layer + NCF layer\n",
    "# 2-layer(including output layer)\n",
    "\n",
    "# hidden layer + active layer(RELU) + output\n",
    "# latent vector dim: 32\n",
    "# input dim: 64\n",
    "\n",
    "class Neural_Collaborative_Filtering(nn.Module):\n",
    "    def __init__(self, n_users, n_movies):\n",
    "    '''\n",
    "    n_users = # of users\n",
    "    n_movies = # of movies\n",
    "    '''\n",
    "        super().__init__()\n",
    "        # convert all users and items into 32-dim learnable latent factors(vectors)\n",
    "        self.user_embedding = nn.Embedding(n_users, 32)\n",
    "        self.movie_embedding = nn.Embedding(n_movies, 32)\n",
    "    \n",
    "        # Neural network for rating prediction\n",
    "        self.fc1 = nn.Linear(64,32) # 64 = user_i embedding + movie_j embedding\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2= nn.Linear(32,1)\n",
    "    \n",
    "    def forward(self, users, movies, ratings = None):\n",
    "        user_embedding = self.user_embedding(users)\n",
    "        movie_embedding = self.movie_embedding(movies)\n",
    "        input_embedding = torch.cat([user_embedding, movie_embedding], dim = 1)\n",
    "        \n",
    "        hidden_feature = self.fc1(input_embedding)\n",
    "        hidden_feature = self.relu(hidden_feature)\n",
    "\n",
    "        output = self.fc2(hidden_feature) # output is prediction\n",
    "\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1a45f-5ad6-494f-b613-b0d4af4cbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 코드가 있는데 딱히 특별한건 없는듯. 아래 정도만 다른 분야와 살짝 다름.\n",
    "    ...\n",
    "    prediction = model(train_data['users'], train_data['movies'])\n",
    "    ground_truth = train_data['ratings'].view(batch_size,-1).to(torch.float32)\n",
    "    ...\n",
    "    loss = loss_func(prediction, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334e96a-3e9b-4736-b9b0-6bfe26dfd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 코드는 그냥 복붙 그래도 한번씩 살펴보긴 할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdc8d2-a8db-4d7d-b104-df3d010cd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "user_est_true = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batched_data in enumerate(test_loader):\n",
    "        users = batched_data['users']\n",
    "        movies = batched_data['movies']\n",
    "        ratings = batched_data['ratings']\n",
    "\n",
    "        model_output = model(batched_data['users'], batched_data[\"movies\"])\n",
    "\n",
    "        for i in range(len(users)):\n",
    "            user_id = users[i].item()\n",
    "            movie_id = movies[i].item()\n",
    "            pred_rating = model_output[i][0].item()\n",
    "            true_rating = ratings[i].item()\n",
    "\n",
    "            user_est_true[user_id].append((pred_rating, true_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc68cb-f4a3-4114-b380-f650cf0746db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "\n",
    "    # recall@K\n",
    "    k= 10\n",
    "    threshold = 3.5 # relevant item criterion\n",
    "\n",
    "    for user_id, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse =True)\n",
    "\n",
    "        # get the number for real relevant items = denominator of recall@k\n",
    "        n_real_relevant= sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # k recommended ratings\n",
    "        recommended_k = user_ratings[:k]\n",
    "\n",
    "        # get the number of recommented item that is actually relevant with real relevant.\n",
    "        n_real_relevant_in_top_k = sum((true_r >= threshold) for (est, true_r) in recommended_k)\n",
    "\n",
    "        # precision@k\n",
    "        precisions[user_id] = n_real_relevant_in_top_k / 10\n",
    "        # recall@k\n",
    "        if n_real_relevant:\n",
    "            recalls[user_id] = n_real_relevant_in_top_k / n_real_relevant\n",
    "        else:\n",
    "            recalls[user_id] = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
