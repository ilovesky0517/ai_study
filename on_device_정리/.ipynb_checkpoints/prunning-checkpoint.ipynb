{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399dc04e-6fcc-4331-9d11-fc9661af0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Pruning : 가중치의중요도를판단하는기준을이해하고 \n",
    "                이를통해불필요한연산을제거하는과정을이해하고있나\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33428439-908d-4874-96a6-bbd9fb75be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[실습 1] Fine-grained Pruning 구현\n",
    "Fine-grained Pruning은 신경망의 가중치를 개별적으로 제거하는 기법입니다. \n",
    "각 가중치의 크기(Magnitude)를 기준으로 중요도를 평가하고, \n",
    "지정된 희소도(sparsity)에 따라 중요도가 낮은 가중치들을 0으로 만듭니다. \n",
    "이를 통해 모델의 크기를 줄이고 연산량을 감소시킬 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3e9eb-640b-4297-9b80-97657ae2c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 요약 \"\"\"\n",
    "### CNN\n",
    "def prune_weight_fine_grained(weight: torch.Tensor, sparsity: float) -> None:\n",
    "    # 신경망의 가중치를 개별적으로 제거\n",
    "    importance = torch.abs(weight)\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_pruned_elements)[0]\n",
    "#############################################################################    \n",
    "def prune_weight_vector_level(weight: torch.Tensor, sparsity: float) -> None:\n",
    "    # 가중치 벡터 단위로 Pruning을 수행\n",
    "    importance = weight.abs().sum(dim=(3,), keepdim=True)\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_pruned_vectors)[0]\n",
    "    ...\n",
    "    mask = mask.expand_as(weight)\n",
    "#############################################################################\n",
    "def prune_weight_kernel_level(weight: torch.Tensor, sparsity: float) -> None:\n",
    "    importance = weight.abs().sum(dim=(2, 3), keepdim=True)\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_pruned_kernels)[0]\n",
    "    ...\n",
    "    mask = mask.expand_as(weight)\n",
    "#############################################################################  \n",
    "def prune_weight_channel_level(weight: torch.Tensor, sparsity: float) -> None:\n",
    "    importance = weight.abs().sum(dim=(0, 2, 3), keepdim=True)\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_pruned_channels)[0]\n",
    "    ...\n",
    "    mask = mask.expand_as(weight)\n",
    "#############################################################################\n",
    "class FineGrainedPrunerV2:\n",
    "    importance = torch.abs(all_weights)\n",
    "    threshold = torch.kthvalue(importance, num_zeros)[0]\n",
    "    ...\n",
    "                    mask = torch.abs(param.data) > threshold\n",
    "#############################################################################\n",
    "## LLM\n",
    "def prune_magnitude_opt(model, sparsity):\n",
    "    importance = torch.abs(W)\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_zeros)[0]\n",
    "#############################################################################\n",
    "def prune_wanda_opt(model, sparsity, input_feat):\n",
    "    row, col = W.shape\n",
    "    num_zeros_per_row = round(col * sparsity)\n",
    "    importance = torch.abs(W) * input_feat[n]\n",
    "    threshold = torch.kthvalue(importance, num_zeros_per_row, dim=1)[0]\n",
    "    mask = importance > threshold.reshape(row, 1)\n",
    "#############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85936e-de6a-4e91-8294-640ae2423635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weight_fine_grained(weight: torch.Tensor, sparsity: float) -> None:\n",
    "    \"\"\"가중치 텐서에 대해 fine-grained pruning을 수행하는 함수\n",
    "\n",
    "    Args:\n",
    "        weight: pruning할 가중치 텐서\n",
    "        sparsity: pruning할 비율 (0~1 사이 값)\n",
    "\n",
    "    Returns:\n",
    "        pruning mask 텐서\n",
    "    \"\"\"\n",
    "    # sparsity 값을 0~1 사이로 제한\n",
    "    sparsity = min(1.0, max(0.0, sparsity))\n",
    "\n",
    "    # 특수한 경우 처리\n",
    "    if sparsity == 1.0:  # 모든 가중치를 제거\n",
    "        weight.zero_()\n",
    "        return torch.zeros_like(weight)\n",
    "    elif sparsity == 0.0:  # 모든 가중치를 유지\n",
    "        return torch.ones_like(weight)\n",
    "\n",
    "    ##################### YOUR CODE STARTS HERE #####################\n",
    "    # 제거할 원소 개수를 계산하세요.\n",
    "    # hint: round() 함수를 사용하세요.\n",
    "    num_pruned_elements = round(weight.numel() * sparsity)\n",
    "\n",
    "    # 가중치의 중요도를 절댓값으로 importance 계산\n",
    "    # hint: torch.abs() 함수를 사용하세요.\n",
    "    importance = torch.abs(weight)\n",
    "\n",
    "    # pruning trheshold를 계산하세요.\n",
    "    # hint: torch.kthvalue() 함수를 사용하세요.\n",
    "    # kthvalue의 결과를 (값, 인덱스) 인데 그 중 값만 가져오겠다는 의미\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_pruned_elements)[0]\n",
    "    #threshold, my_idx = torch.kthvalue(importance.flatten(), num_pruned_elements)\n",
    "\n",
    "\n",
    "    # threshold보다 큰 값들은 유지(1), 작은 값들은 제거(0)하는 마스크 생성\n",
    "    # hint: 부등호를 사용하세요.\n",
    "    mask = importance > threshold\n",
    "    ##################### YOUR CODE ENDS HERE #######################\n",
    "\n",
    "    # 마스크를 적용하여 pruning 수행\n",
    "    weight.mul_(mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# 마스크 생성 및 시각화\n",
    "mask_fine_grained = prune_weight_fine_grained(weight.clone(), prune_sparsity)\n",
    "draw_weight_distribution(mask_fine_grained, title=\"Fine-grained Pruning Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04271672-1978-4838-a6c4-bd0790af0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weight_vector_level(weight: torch.Tensor, sparsity: float) -> None:\n",
    "    \"\"\"벡터 단위로 가중치를 프루닝하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        weight: 프루닝할 가중치 텐서\n",
    "        sparsity: 프루닝할 비율 (0~1 사이 값)\n",
    "\n",
    "    Returns:\n",
    "        프루닝 마스크 텐서\n",
    "    \"\"\"\n",
    "    # sparsity 값을 0~1 사이로 제한\n",
    "    sparsity = min(1.0, max(0.0, sparsity))\n",
    "\n",
    "    # 특수한 경우 처리\n",
    "    if sparsity == 1.0:  # 모든 가중치를 제거\n",
    "        weight.zero_()\n",
    "        return torch.zeros_like(weight)\n",
    "    elif sparsity == 0.0:  # 모든 가중치를 유지\n",
    "        return torch.ones_like(weight)\n",
    "\n",
    "    # 제거할 벡터의 개수 계산\n",
    "    num_vectors = weight.shape[0] * weight.shape[1] * weight.shape[2]\n",
    "    num_pruned_vectors = round(num_vectors * sparsity)\n",
    "\n",
    "    # 각 벡터의 중요도를 절댓값 합으로 계산\n",
    "    importance = weight.abs().sum(dim=(3,), keepdim=True)\n",
    "\n",
    "    # pruning trheshold를 계산\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_pruned_vectors)[0]\n",
    "\n",
    "    # threshold보다 큰 벡터는 유지(1), 작은 벡터는 제거(0)\n",
    "    mask = importance > threshold\n",
    "\n",
    "    # 마스크를 가중치와 동일한 크기로 확장\n",
    "    mask = mask.expand_as(weight)\n",
    "\n",
    "    # 마스크를 적용하여 프루닝 수행\n",
    "    weight.mul_(mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "mask_vector_level = prune_weight_vector_level(weight.clone(), prune_sparsity)\n",
    "draw_weight_distribution(mask_vector_level, title=\"Vector-level Pruning Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f43f5-5051-48f8-bcd3-3b98b1472370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weight_kernel_level(weight: torch.Tensor, sparsity: float) -> None:\n",
    "    \"\"\"커널 단위로 가중치를 프루닝하는 함수\n",
    "\n",
    "    Args:\n",
    "        weight: 프루닝할 가중치 텐서 (out_channels, in_channels, kernel_h, kernel_w)\n",
    "        sparsity: 프루닝할 비율 (0~1 사이 값)\n",
    "\n",
    "    Returns:\n",
    "        프루닝 마스크 텐서\n",
    "    \"\"\"\n",
    "    sparsity = min(1.0, max(0.0, sparsity))\n",
    "    if sparsity == 1.0:\n",
    "        weight.zero_()\n",
    "        return torch.zeros_like(weight)\n",
    "    elif sparsity == 0.0:\n",
    "        return torch.ones_like(weight)\n",
    "\n",
    "    # 프루닝할 커널 수 계산\n",
    "    num_kernels = weight.shape[0] * weight.shape[1]\n",
    "    num_pruned_kernels = round(num_kernels * sparsity)\n",
    "\n",
    "    # 각 커널의 중요도를 절댓값 합으로 계산 (커널 크기에 대해 합산)\n",
    "    importance = weight.abs().sum(dim=(2, 3), keepdim=True)\n",
    "\n",
    "    # pruning trheshold를 계산\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_pruned_kernels)[0]\n",
    "\n",
    "    # threshold보다 큰 커널은 유지(1), 작은 커널은 제거(0)\n",
    "    mask = importance > threshold\n",
    "\n",
    "    # 마스크를 가중치와 동일한 크기로 확장\n",
    "    mask = mask.expand_as(weight)\n",
    "\n",
    "    # 마스크를 적용하여 프루닝 수행\n",
    "    weight.mul_(mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "mask_kernel_level = prune_weight_kernel_level(weight.clone(), prune_sparsity)\n",
    "draw_weight_distribution(mask_kernel_level, title=\"Kernel-level Pruning Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f03b02-84c2-45ae-9976-3cd05a8b7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weight_channel_level(weight: torch.Tensor, sparsity: float) -> None:\n",
    "    \"\"\"채널 단위 프루닝을 수행하는 함수\n",
    "\n",
    "    Args:\n",
    "        weight: 프루닝할 가중치 텐서 (out_channels, in_channels, kernel_h, kernel_w)\n",
    "        sparsity: 프루닝할 비율 (0~1 사이 값)\n",
    "\n",
    "    Returns:\n",
    "        프루닝 마스크 텐서\n",
    "    \"\"\"\n",
    "    sparsity = min(1.0, max(0.0, sparsity))\n",
    "    if sparsity == 1.0:\n",
    "        weight.zero_()\n",
    "        return torch.zeros_like(weight)\n",
    "    elif sparsity == 0.0:\n",
    "        return torch.ones_like(weight)\n",
    "\n",
    "    # 프루닝할 채널 수 계산\n",
    "    num_channels = weight.shape[1]\n",
    "    num_pruned_channels = round(num_channels * sparsity)\n",
    "\n",
    "    # 각 채널의 중요도를 절댓값 합으로 계산\n",
    "    # (출력 채널, 커널 높이, 커널 너비에 대해 합산)\n",
    "    importance = weight.abs().sum(dim=(0, 2, 3), keepdim=True)\n",
    "\n",
    "    # pruning threshold를 계산\n",
    "    threshold = torch.kthvalue(importance.flatten(), num_pruned_channels)[0]\n",
    "\n",
    "    # threshold보다 큰 채널은 유지(1), 작은 채널은 제거(0)\n",
    "    mask = importance > threshold\n",
    "\n",
    "    # 마스크를 가중치와 동일한 크기로 확장\n",
    "    mask = mask.expand_as(weight)\n",
    "\n",
    "    # 마스크를 적용하여 프루닝 수행\n",
    "    weight.mul_(mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "mask_channel_level = prune_weight_channel_level(weight.clone(), prune_sparsity)\n",
    "draw_weight_distribution(mask_channel_level, title=\"Channel-level Pruning Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512829d1-c0ce-4c49-9c11-6116beecfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineGrainedPrunerV2:\n",
    "    def __init__(self, model, sparsity, global_prune=False):\n",
    "        \"\"\"\n",
    "        전역 또는 레이어별 프루닝을 위한 프루너 클래스\n",
    "\n",
    "        Args:\n",
    "            model: 프루닝할 모델\n",
    "            sparsity: 프루닝 비율 (0~1)\n",
    "            global_prune: 전역 프루닝 여부\n",
    "        \"\"\"\n",
    "        self.masks = FineGrainedPrunerV2.prune(model, sparsity, global_prune)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def apply(self, model):\n",
    "        \"\"\"프루닝 마스크를 모델에 적용\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in self.masks:\n",
    "                param *= self.masks[name]\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def prune(model, sparsity, global_prune):\n",
    "        \"\"\"\n",
    "        전역 또는 레이어별 프루닝 수행\n",
    "\n",
    "        Args:\n",
    "            model: 프루닝할 모델\n",
    "            sparsity: 프루닝 비율 (0~1)\n",
    "            global_prune: 전역 프루닝 여부\n",
    "\n",
    "        Returns:\n",
    "            masks: 프루닝 마스크 딕셔너리\n",
    "        \"\"\"\n",
    "        masks = dict()\n",
    "        if global_prune:\n",
    "            # 모든 2D 이상의 파라미터를 1차원으로 변환하여 수집\n",
    "            parameters_to_prune = []\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.dim() > 1:  # conv, fc 레이어만 프루닝\n",
    "                    parameters_to_prune.append(param.view(-1))\n",
    "\n",
    "            ##################### YOUR CODE STARTS HERE #####################\n",
    "            # 모든 weight를 하나의 텐서로 결합해주세요..model.recover_model()\n",
    "            # hint: torch.cat()을 사용하세요.\n",
    "            all_weights = torch.cat(parameters_to_prune)\n",
    "\n",
    "            # all_weights를 대상으로 global threshold를 구해주세요.\n",
    "            num_elements = all_weights.numel()\n",
    "            num_zeros = round(num_elements * sparsity)\n",
    "            importance = torch.abs(all_weights)\n",
    "            threshold = torch.kthvalue(importance, num_zeros)[0]\n",
    "            ##################### YOUR CODE ENDS HERE #######################\n",
    "\n",
    "            # threshold 기반 마스크 생성\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.dim() > 1:\n",
    "                    mask = torch.abs(param.data) > threshold\n",
    "                    masks[name] = mask\n",
    "        else:\n",
    "            # 레이어별 프루닝 수행\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.dim() > 1: # we only prune conv and fc weights\n",
    "                    masks[name] = prune_weight_fine_grained(param, sparsity)\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267cadd-6fd6-4a0c-b1a2-e9af8de95f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e882b-8cff-40ae-aa35-87cc0b9a1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prune_magnitude_opt(model, sparsity):\n",
    "    for n, m in model.named_modules():\n",
    "        if isinstance(m, nn.Linear) and \"lm_head\" not in n:\n",
    "            W = m.weight.data\n",
    "            ##################### YOUR CODE STARTS HERE #####################\n",
    "            num_elements = W.numel()\n",
    "            num_zeros = round(num_elements * sparsity)\n",
    "            importance = torch.abs(W)\n",
    "            threshold = torch.kthvalue(importance.flatten(), num_zeros)[0]\n",
    "            mask = importance > threshold\n",
    "            ##################### YOUR CODE ENDS HERE #######################\n",
    "            W.mul_(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a860f6e-0116-4eb8-9935-f291d02fc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prune_wanda_opt(model, sparsity, input_feat):\n",
    "    for n, m in model.named_modules():\n",
    "        if isinstance(m, nn.Linear) and \"lm_head\" not in n:\n",
    "            W = m.weight.data\n",
    "            ##################### YOUR CODE STARTS HERE #####################\n",
    "            row, col = W.shape\n",
    "            num_zeros_per_row = round(col * sparsity)\n",
    "            importance = torch.abs(W) * input_feat[n]\n",
    "            threshold = torch.kthvalue(importance, num_zeros_per_row, dim=1)[0]\n",
    "            mask = importance > threshold.reshape(row, 1)\n",
    "            ##################### YOUR CODE ENDS HERE #######################\n",
    "            W.mul_(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07125e56-65fe-4031-87ba-d1c4cbc7ebe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00b3de-f769-41ac-bff3-189209f0541f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
