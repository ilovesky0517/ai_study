{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333dde7-397f-4373-8ae8-0c585317ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2. Quantization for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e4ac2-6087-4333-8450-5273b5acd4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Goals\n",
    "본 실습에서는 CNN(Convolutional Neural Network)을 **양자화(Quantization)**하여 모델의 크기와 실행 시간을 줄이는 방법을 실습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7ecbc-9e45-4c94-bf83-9502c3a74c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Contents\n",
    "1. **Uniform Quantization**\n",
    "  - **Linear quantization**을 구현하고 적용합니다.\n",
    "  - **Linear quantization**을 위한 **Integer-only inference**를 구현하고 적용합니다.\n",
    "2. **Non-uniform Quantization**\n",
    "  - **K-means quantization**을 구현하고 적용합니다.\n",
    "3. **Quantization with PyTorch API**\n",
    "  - **Post-Training Quantization** (PTQ)\n",
    "  - **Quantization-Aware Training** (QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de478ab-5b16-44e9-84a7-ae3a14106be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "print('Installing torchprofile...')\n",
    "subprocess.check_call([\"pip\", \"install\", \"torchprofile\"])\n",
    "print('Installing fast-pytorch-kmeans...')\n",
    "subprocess.check_call([\"pip\", \"install\", \"fast-pytorch-kmeans\"])\n",
    "print('All required packages have been successfully installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bff66-213c-4287-8d5c-9fc528b2a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172a211-8f18-48e3-84dd-0963e41c2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bdc431-0a58-4b5e-ae1b-e86a80b3795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "  ARCH = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    def add(name: str, layer: nn.Module) -> None:\n",
    "      layers.append((f\"{name}{counts[name]}\", layer))\n",
    "      counts[name] += 1\n",
    "\n",
    "    in_channels = 3\n",
    "    for x in self.ARCH:\n",
    "      if x != 'M':\n",
    "        # conv-bn-relu\n",
    "        add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n",
    "        add(\"bn\", nn.BatchNorm2d(x))\n",
    "        add(\"relu\", nn.ReLU(True))\n",
    "        in_channels = x\n",
    "      else:\n",
    "        # maxpool\n",
    "        add(\"pool\", nn.MaxPool2d(2))\n",
    "    add(\"avgpool\", nn.AvgPool2d(2))\n",
    "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "    self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    # backbone: [N, 3, 32, 32] => [N, 512, 2, 2]\n",
    "    x = self.backbone(x)\n",
    "\n",
    "    # avgpool: [N, 512, 2, 2] => [N, 512]\n",
    "    # x = x.mean([2, 3])\n",
    "    x = x.view(x.shape[0], -1)\n",
    "\n",
    "    # classifier: [N, 512] => [N, 10]\n",
    "    x = self.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81086e9-a5c3-4a5b-9ad7-6d4848549fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CIFAR-10 데이터셋 로드 및 전처리\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])]\n",
    ")\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"D:\\\\data\", train=True, download=True, transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"D:\\\\data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "# 모델 학습 함수 정의\n",
    "def train_model(model, trainloader, epochs=5):\n",
    "    try:\n",
    "        device = next(model.parameters()).device\n",
    "    except StopIteration:\n",
    "        try:\n",
    "            device = next(model.buffers()).device\n",
    "        except StopIteration:\n",
    "            # 파라미터나 버퍼가 모두 없으면 기본적으로 CPU로 설정\n",
    "            device = torch.device(\"cpu\")\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
    "    return model\n",
    "\n",
    "# 모델 평가 함수 정의\n",
    "def evaluate_model(model, testloader):\n",
    "    try:\n",
    "        device = next(model.parameters()).device\n",
    "    except StopIteration:\n",
    "        try:\n",
    "            device = next(model.buffers()).device\n",
    "        except StopIteration:\n",
    "            # 파라미터나 버퍼가 모두 없으면 기본적으로 CPU로 설정\n",
    "            device = torch.device(\"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71468933-08c7-451f-a8a4-1692088bf60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  extra_preprocess = None\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    if torch.cuda.is_available():\n",
    "      inputs = inputs.cuda()\n",
    "      targets = targets.cuda()\n",
    "    if extra_preprocess is not None:\n",
    "        for preprocess in extra_preprocess:\n",
    "            inputs = preprocess(inputs)\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3782090-6393-42db-b2c1-be826abfd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_flops(model, inputs):\n",
    "    num_macs = profile_macs(model, inputs)\n",
    "    return num_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb85319-b8d7-4bce-b85b-bd079c5a1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model: nn.Module, data_width=32):\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    \"\"\"\n",
    "    num_elements = 0\n",
    "    for param in model.parameters():\n",
    "        num_elements += param.numel()\n",
    "    return num_elements * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fead37-6ced-4c03-ab72-755584b24e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://www.dropbox.com/scl/fi/ui1fkdvwlhd55fncto8fa/vgg_cifar10_pretrained.pth?rlkey=gu58eq42mo9riot1mexijw79k&st=gak0oq04&dl=1\" -o \"D:\\\\data\\\\vgg_cifar10_pretrained.pth\"\n",
    "checkpoint = torch.load('D:\\\\data\\\\vgg_cifar10_pretrained.pth', map_location=\"cpu\")\n",
    "model = VGG().cuda()\n",
    "print(f\"=> loading checkpoint 'vgg_cifar10_pretrained.pth'\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "recover_model = lambda : model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "#TORCH_HUB_REPO = \"SKKU-ESLAB/pytorch-models\"\n",
    "#MODEL_NAME = \"cifar10_vgg9_bn\" # cifar10_resnet20, cifar10_vgg11_bn\n",
    "#\n",
    "#model = torch.hub.load(TORCH_HUB_REPO, MODEL_NAME, pretrained=True)\n",
    "#if torch.cuda.is_available():\n",
    "#    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4da54-e864-4d54-baaf-8f8a0424d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "image_size = 32\n",
    "transforms = {\n",
    "    \"train\": Compose([\n",
    "        RandomCrop(image_size, padding=4),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "    ]),\n",
    "    \"test\": ToTensor(),\n",
    "}\n",
    "\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "    dataset[split] = CIFAR10(\n",
    "        root=\"D:\\\\data\\\\cifar10\",\n",
    "        train=(split == \"train\"),\n",
    "        download=True,\n",
    "        transform=transforms[split],\n",
    "    )\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "targets = np.array(dataset['test'].targets)\n",
    "\n",
    "indices = []\n",
    "for class_idx in range(num_classes):\n",
    "    class_indices = np.where(targets == class_idx)[0]\n",
    "    selected_indices = np.random.choice(class_indices, len(class_indices) // 100, replace=False)\n",
    "    indices.extend(selected_indices)\n",
    "\n",
    "dataset['test'] = Subset(dataset['test'], indices)\n",
    "\n",
    "dataloader = {}\n",
    "for split in ['train', 'test']:\n",
    "    dataloader[split] = DataLoader(\n",
    "        dataset[split],\n",
    "        batch_size=512,\n",
    "        shuffle=(split == 'train'),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e0caa-1580-48d3-a466-62af7cd44387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qconfig_printer(qconfig):\n",
    "    # 가중치(weight) 관찰자 인스턴스 생성 및 속성 조회\n",
    "    weight_observer_instance = qconfig.weight()\n",
    "    weight_observer = weight_observer_instance.__class__.__name__\n",
    "    weight_dtype = weight_observer_instance.dtype\n",
    "    weight_qscheme = weight_observer_instance.qscheme\n",
    "    weight_quant_min = weight_observer_instance.quant_min\n",
    "    weight_quant_max = weight_observer_instance.quant_max\n",
    "\n",
    "    # 활성화(activation) 관찰자 인스턴스 생성 및 속성 조회\n",
    "    activation_observer_instance = qconfig.activation()\n",
    "    activation_observer = activation_observer_instance.__class__.__name__\n",
    "    activation_dtype = activation_observer_instance.dtype\n",
    "    activation_qscheme = activation_observer_instance.qscheme\n",
    "    activation_quant_min = activation_observer_instance.quant_min\n",
    "    activation_quant_max = activation_observer_instance.quant_max\n",
    "\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Weight Observer: {weight_observer}\")\n",
    "    print(f\"Weight dtype: {weight_dtype}\")\n",
    "    print(f\"Weight qscheme: {weight_qscheme}\")\n",
    "    print(f\"Weight quant_min: {weight_quant_min}\")\n",
    "    print(f\"Weight quant_max: {weight_quant_max}\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(f\"Activation Observer: {activation_observer}\")\n",
    "    print(f\"Activation dtype: {activation_dtype}\")\n",
    "    print(f\"Activation qscheme: {activation_qscheme}\")\n",
    "    print(f\"Activation quant_min: {activation_quant_min}\")\n",
    "    print(f\"Activation quant_max: {activation_quant_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24303e8-2f6e-4f43-ae21-72684bdc4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp32_model_accuracy = evaluate(model, dataloader['test'])\n",
    "fp32_model_size = get_model_size(model)\n",
    "print(f\"fp32 model의 정확도={fp32_model_accuracy:.2f}%\")\n",
    "print(f\"fp32 model의 크기={fp32_model_size/MiB:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c4b32-8f96-4a08-b6fd-7e967bdede7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantized_range(bitwidth):\n",
    "    quantized_max = (1 << (bitwidth - 1)) - 1\n",
    "    quantized_min = -(1 << (bitwidth - 1))\n",
    "    return quantized_min, quantized_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce399d3-b371-4166-86ca-1594116441b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## [실습 1] Linear quantization 구현\n",
    "\"\"\"\n",
    "다음 linear quantization 함수를 완성해 주세요.\n",
    "\n",
    "**Hint**:\n",
    "*   $r=S(q-Z)$ 로 부터, $q = r/S + Z$ 를 도출할 수 있습니다.\n",
    "*   $r$ 과 $S$ 는 모두 부동 소수점이므로, 정수 $Z$ 을 부동 소수점 $r/S$ 에 직접 더할 수 없습니다. 그러므로 $q = \\mathrm{int}(\\mathrm{round}(r/S)) + Z$ 와 같이 계산해야 합니다.\n",
    "*   [`torch.FloatTensor`](https://pytorch.org/docs/stable/tensors.html) 에서 [`torch.IntTensor`]\n",
    "(https://pytorch.org/docs/stable/tensors.html) 로 변환하려면, 먼저 [`torch.round()`]\n",
    "(https://pytorch.org/docs/stable/generated/torch.round.html#torch.round), [`torch.Tensor.round()`]\n",
    "(https://pytorch.org/docs/stable/generated/torch.Tensor.round.html#torch.Tensor.round), 또는 [`torch.Tensor.round_()`]\n",
    "(https://pytorch.org/docs/stable/generated/torch.Tensor.round_)을 사용하여 모든 값을 부동 소수점 정수로 반올림 한 후, [`torch.Tensor.to(torch.int8)`]\n",
    "(https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to) 를 사용하여 데이터 유형을 [`torch.float`]\n",
    "(https://pytorch.org/docs/stable/tensors.html) 에서 [`torch.int8`](https://pytorch.org/docs/stable/tensors.html)로 변환해야 합니다.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93e788-9423-47d1-b934-a0576f0df33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92a106-913c-4e01-a898-4ee9a69fe515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17e07e-b50d-4c09-bbd0-be567dcdbb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
