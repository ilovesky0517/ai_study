{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d6ebe3-d2a6-4474-8114-7b577e7889fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\miniconda3\\lib\\site-packages (1.0)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\miniconda3\\lib\\site-packages (from yfinance) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\miniconda3\\lib\\site-packages (from yfinance) (2.4.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\miniconda3\\lib\\site-packages (from yfinance) (2.32.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\miniconda3\\lib\\site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\miniconda3\\lib\\site-packages (from yfinance) (4.5.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\miniconda3\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\miniconda3\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\miniconda3\\lib\\site-packages (from yfinance) (3.19.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\miniconda3\\lib\\site-packages (from yfinance) (4.14.3)\n",
      "Requirement already satisfied: curl_cffi<0.14,>=0.7 in c:\\miniconda3\\lib\\site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\miniconda3\\lib\\site-packages (from yfinance) (6.33.4)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\miniconda3\\lib\\site-packages (from yfinance) (16.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\miniconda3\\lib\\site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\miniconda3\\lib\\site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2025.11.12)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\miniconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\miniconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\miniconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance) (2.23)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\miniconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\miniconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\miniconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\miniconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\miniconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b29415bc-7222-47ed-bf2c-b6d99d0601cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6276\\3398957993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# For handling dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "# Math and data preprocessing libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# For handling dataset\n",
    "import yfinance as yf\n",
    "from datetime import date\n",
    "\n",
    "# For visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics \\\n",
    "import root_mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb7961-c1e0-4a82-acdc-76d53c1df802",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if \\\n",
    "                      torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448dd09-62c2-46e8-8f19-d75bd3db4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "df = yf.download('GOOG', start=start_date, end=end_date)\n",
    "\n",
    "# Inspect the data\n",
    "print()\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ebd1a-9d66-4d42-a604-d90e0b74b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 1\n",
    "nrows = int(round(df.shape[1] / ncols, 0))\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, \\\n",
    "                       sharex=True, figsize=(14, 7))\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    sns.lineplot(data=df.iloc[:, i], ax=ax)\n",
    "    ax.tick_params(axis=\"x\", rotation=30, \\\n",
    "                   labelsize=10, length=0)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6835f-82cc-4423-9798-4804963019f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_ratio = 0.8\n",
    "training_data_len = math.ceil(len(df) * train_ratio)\n",
    "\n",
    "# Splitting the dataset\n",
    "train_data = df[:training_data_len][['Open']]\n",
    "test_data = df[training_data_len:][['Open']]\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "# (1006, 1)\n",
    "# (251, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bae78c-fdf1-4c81-af2b-3d695aa4561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_scaled = scaler.fit_transform(train_data.values)\n",
    "test_scaled = scaler.transform(test_data.values)\n",
    "\n",
    "for v in train_data.values[:5, 0]:\n",
    "  print(f'{v:6.3f}', end=' ')\n",
    "print()\n",
    "# 66.681 66.995 67.101 69.484 69.193\n",
    "\n",
    "for v in train_scaled[:5, 0]:\n",
    "  print(f'{v:6.3f}', end=' ')\n",
    "print()\n",
    "# 0.144  0.147  0.148  0.172  0.169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a699f2-cf2a-4d86-9282-64a8ad889478",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "\n",
    "def convert_data_into_tensors(data_seq):\n",
    "    features, labels = [],[]\n",
    "    for i in range(len(data_seq) - sequence_length):\n",
    "        features.append(data_seq[i: i+sequence_length])\n",
    "        labels.append(data_seq[i+sequence_length,0])\n",
    "    features, labels = np.array(features), np.array(labels)\n",
    "    \n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return features, labels\n",
    "\n",
    "X_train, Y_train = convert_data_into_tensor(train_scaled)\n",
    "X_test, Y_test = convert_data_into_tensor(test_scaled)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# torch.Size([956, 50, 1])\n",
    "# torch.Size([956])\n",
    "# torch.Size([201, 50, 1])\n",
    "# torch.Size([201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafc43e-59d4-45d0-8fe9-ee3a7ac59a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "def to_loader(x, y, batch_size, shuffle):\n",
    "    dataset = torch.utils.data.TensorDataset(x, y)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle)\n",
    "\n",
    "train_loader = to_loader(X_train, Y_train, batch_size, shuffle=True)\n",
    "test_loader = to_loader(X_test, Y_test, batch_size, shuffle=False)\n",
    "\n",
    "print(train_loader)\n",
    "print(test_loader)\n",
    "\n",
    "# <torch.utils.data.dataloader.DataLoader object at 0x78eacd13fdd0>\n",
    "# <torch.utils.data.dataloader.DataLoader object at 0x78eacd13fd50>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc236e-5fc4-4fe0-ae6f-1408f5a0c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "\n",
    "manual_seed = 42\n",
    "torch.manual_seed(manual_seed)\n",
    "np.random.seed(manual_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35893761-3c2d-429e-beea-05f75428756a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = X_train.shape[-1]\n",
    "num_layers = 2\n",
    "hidden_size = 64\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # (lstm): LSTM(1, 64, num_layers=2, batch_first=True)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        # (linear): Linear(in_features=64, out_features=1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return = self.linear(out)\n",
    "    \n",
    "model = LSTMModel(input_size, hidden_size, num_layers).to(device)\n",
    "print(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c222b-65f5-49af-998f-470b87c37d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader):\n",
    "    train_hist = []\n",
    "    test_hist = []\n",
    "    num_epochs = 10\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0.0\n",
    "        total_test_loss = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            # (1) Move input and target tensors to the device (e.g., GPU)\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            # (2) Pass the input (batch_x) through the model\n",
    "            #     The model outputs shape [batch_size, sequence_length, 1]\n",
    "            #     Take the prediction at the last timestep (index -1) and feature index 0\n",
    "            #     → model(batch_x)[:, -1, 0]\n",
    "            pred = model(batch_x)[:, -1, 0]\n",
    "            \n",
    "            # (3) Compute the loss between pred and batch_y by using loss_fn\n",
    "            loss = loss_fn(pred, batch_y)\n",
    "            \n",
    "            # (4) Clear previous gradients to avoid accumulation\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # (5) Perform backpropagation to compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # (6) Update the model parameters using the optimizer\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "        avg_loss = total_train_loss / len(train_loader)\n",
    "        train_hist.append(avg_loss)\n",
    "        \n",
    "        # evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in test_loader:\n",
    "                # (1) Move input and target tensors to the device (e.g., GPU)\n",
    "                test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "                \n",
    "                # (2) Pass the input (test_x) through the model\n",
    "                #     The model outputs shape [batch_size, sequence_length, 1]\n",
    "                #     Take the prediction at the last timestep (index -1) and feature index 0\n",
    "                #     → model(test_x)[:, -1, 0]\n",
    "                test_pred = model(test_x)[:, -1, 0]\n",
    "                \n",
    "                # (3) Compute the loss between test_pred and test_y by using loss_fn\n",
    "                test_loss = loss_fn(test_pred, test_y)\n",
    "                \n",
    "                total_test_loss += test_loss.item()\n",
    "            avg_test_loss = total_test_loss / len(test_loader)\n",
    "            test_hist.append(avg_test_loss)\n",
    "            \n",
    "            print(f'Epoch {epoch + 1:2d}/{num_epochs} - Training Loss: {avg_loss:.4f}, Test Loss: {avg_test_loss:.4f}')\n",
    "        \n",
    "        x = np.linspace(1, num_epochs, num_epochs)\n",
    "        plt.plot(x, train_hist, scalex=True, label=\"Training loss\")\n",
    "        plt.plot(x, test_hist, label=\"Test loss\")\n",
    "        plt.legend()\n",
    "\n",
    "train(model, train_loader, test_loader)\n",
    "        \n",
    "# Epoch  1/10 - Training Loss: 0.1736, Test Loss: 0.4874\n",
    "# Epoch  2/10 - Training Loss: 0.0388, Test Loss: 0.0877\n",
    "# Epoch  3/10 - Training Loss: 0.0078, Test Loss: 0.0072\n",
    "# Epoch  4/10 - Training Loss: 0.0031, Test Loss: 0.0097\n",
    "# Epoch  5/10 - Training Loss: 0.0023, Test Loss: 0.0123\n",
    "# Epoch  6/10 - Training Loss: 0.0020, Test Loss: 0.0188\n",
    "# Epoch  7/10 - Training Loss: 0.0020, Test Loss: 0.0111\n",
    "# Epoch  8/10 - Training Loss: 0.0021, Test Loss: 0.0165\n",
    "# Epoch  9/10 - Training Loss: 0.0018, Test Loss: 0.0225\n",
    "# Epoch 10/10 - Training Loss: 0.0017, Test Loss: 0.0177    \n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524a031-a056-4cd0-942a-56ac00ce91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecasting Visualization\n",
    "# plt 관련 내용은 복습 필요(단순 타이핑)\n",
    "\n",
    "def plot_forecasting(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    num_forecast_steps = 30\n",
    "    input_data = X_test[-num_forecast_steps].cpu().numpy().squeeze()\n",
    "    \n",
    "    forecasted_values = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(2*num_forecast_steps):\n",
    "            input_tensor = torch.as_tensor(input_data).view(1,-1,1).to(device)\n",
    "            predicted = model(input_tensor)[0,-1, 0].item()\n",
    "            \n",
    "            forecasted_values.append(predicted)\n",
    "            input_data = np.roll(input_data, shift=-1)\n",
    "            \n",
    "            if i<num_forecast_steps:\n",
    "                input_data[-1] = y_test[-num_forecast_steps+i]\n",
    "            else:\n",
    "                input_data[-1] = predicted\n",
    "    df_out = df.copy()\n",
    "    last_data = df_out.index[-1]\n",
    "    future_dates = pd.date_range(start=last_date + pd.DateOffset(1), periods=num_forecast_steps)\n",
    "    combined_dates = df_out.index.append(future_dates)\n",
    "    plt.rcParams['figure.figsize'] = [14, 4]\n",
    "    plt.plot(test_data.index[-100:-30], test_data[-100:-30], label = \"test_data\", color = \"b\")\n",
    "    plt.plot(test_data.index[-30:], test_data.iloc[-30:], label='actual values', color='green')\n",
    "    \n",
    "    forecasted_cases = scaler.inverse_transform(np.expand_dims(forecasted_values, axis=0)).flatten()\n",
    "    plt.plot(combined_dates[-60:], forecasted_cases, label='forecasted values', color='red')\n",
    "\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.title('Time Series Forecasting')\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_forecasting(model, X_test, y_test)\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad6bd9-13ca-4e6b-ace7-cd47ab8e8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "def test(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test = X_test.to(device)\n",
    "        y_hat = model(X_test)\n",
    "        test_predictions = y_hat[:, -1, 0]\n",
    "        \n",
    "    test_predictions = test_predictions.cpu().numpy()\n",
    "    y_test = y_test.cpu().numpy()\n",
    "    \n",
    "    rmse = root_mean_squared_error(y_test, test_predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, test_predictions)\n",
    "    \n",
    "    return rmse, mape\n",
    "\n",
    "rmse, mape = test(model, X_test, y_test)\n",
    "\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MAPE: {mape:.4f}')\n",
    "\n",
    "# RMSE: 0.1194\n",
    "# MAPE: 0.0847\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a83c6-9bcb-4659-b37a-13bc665d83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other Models: CNN, RNN\n",
    "\n",
    "class Conv1DModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Conv1DModel, self).__init__()\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=hidden_size, kernel_size=2, stride=1)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.conv1d(x)\n",
    "        x = x.transpose(1,2)\n",
    "        return self.fc(x)      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760cf31-591a-4a8b-b1f4-24b21fcf8aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[-1]\n",
    "num_layers = 2\n",
    "hidden_size = 64\n",
    "\n",
    "model = Conv1DModel(input_size, hidden_size).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da34a74-6ce5-46a7-a35c-dc6ada13bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0eb4d-c24c-498b-8955-419007933886",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b0ea2-5a9a-4d0a-8f4e-3d5a78ec3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, mape = test(model, X_test, y_test)\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MAPE: {mape:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678388dc-fbbb-4b0d-8be9-bbf14aec2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d6abf-ebfd-48a1-8983-2cd47c910908",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[-1]\n",
    "num_layers = 2\n",
    "hidden_size = 64\n",
    "\n",
    "model = RNNModel(input_size, hidden_size, num_layers).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef260c-4c84-4d78-bc89-647b614c2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98f18a-4c37-4600-8fce-7508f1682dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07dbdda-b77d-468d-8835-964f7d552db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, mape = test(model, X_test, y_test)\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MAPE: {mape:.4f}')\n",
    "\n",
    "# RMSE: 0.0862\n",
    "# MAPE: 0.0606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41af98e-b753-40d8-94d8-4d306a2d6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional (Encoder-Decoder)\n",
    "#Data Preprocessing\n",
    "\n",
    "sequence_length = 50\n",
    "target_len = 10\n",
    "\n",
    "def create_enc_dec_sequences(data):\n",
    "    features, labels = [],[]\n",
    "    for i in range(len(data) - sequence_length - target_len):\n",
    "        features.append(data[i:i+sequence_length])\n",
    "        labels.append(data[i+sequence_length:i+sequence_length + target_length])\n",
    "        \n",
    "    features = np.array(features, dtype=float32)\n",
    "    labels = np.array(labels, dtype=float32)\n",
    "    \n",
    "    features = torch.tensor(features, dtype = torch.float32)\n",
    "    labels = torch.tensor(labels, dtype = torch.float32)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "X_train, y_train = create_enc_dec_sequence(train_scaled)\n",
    "X_test, y_test = create_end_dec_sequence(test_scaled)\n",
    "print(X_train_.shape)\n",
    "print(y_train_.shape)\n",
    "print(X_test_.shape)\n",
    "print(y_test_.shape)\n",
    "\n",
    "train_loader = to_loader(X_train, y_train, batch_size, shuffle=True)\n",
    "test_loader = to_loader(X_test, y_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03e748-16b5-4cba-b1d8-dc2652c7c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        -, h = self.rnn(x)\n",
    "        return h\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, input_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, h = self.rnn(x, h)\n",
    "        out = self.fc(out)\n",
    "        return out, h\n",
    "    \n",
    "class RNNRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNNRNN, self).__init__()\n",
    "        self.encoder = EndocerRNN(input_size, hidden_size, num_layers)\n",
    "        self.decoder = DecoderRNN(input_size, hidden_size, num_layers)\n",
    "        \n",
    "    def forward(self, source, target_len):\n",
    "        h = self.encoder(source)\n",
    "        predictions = []\n",
    "        input = source[:, -1, :].unsqueeze(1)\n",
    "        for t in range(target_len):\n",
    "            out, h = self.decoder(input, h)\n",
    "            predictions.append(out.squeeze(1))\n",
    "            input = out\n",
    "        outputs = torch.stack(predictions, dim=1)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "model_ = RNNRNN(input_size, hidden_size, num_layers),to(device)\n",
    "print(model_)\n",
    "\n",
    "# RNNRNN(\n",
    "#   (encoder): EncoderRNN(\n",
    "#     (rnn): RNN(1, 64, num_layers=2, batch_first=True)\n",
    "#   )\n",
    "#   (decoder): DecoderRNN(\n",
    "#     (rnn): RNN(1, 64, num_layers=2, batch_first=True)\n",
    "#     (fc): Linear(in_features=64, out_features=1, bias=True)\n",
    "#   )\n",
    "# )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba6a9c-bdff-40a3-be34-e20b47bc6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "def train_(model, train_loader, test_loader):\n",
    "    train_hist = []\n",
    "    test_hist = []\n",
    "    num_epochs = 10\n",
    "    loss_fn = nn.MSELoss(reduction = 'mean')\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0.0\n",
    "        total_test_loss = 0.0\n",
    "        \n",
    "        #train\n",
    "        model.train()\n",
    "        for batch_x, batch_y in train_loader :\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            pred = model(batch_x, batch_y.shape[1])\n",
    "            loss = loss_fn(pred, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_train_loss / len(train_loader)\n",
    "        train_hist.append(avg_loss)\n",
    "        \n",
    "        \n",
    "        #evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in test_loader :\n",
    "                test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "                test_pred = model(test_x, target_len)\n",
    "                test_loss = loss_fn(test_pred, test_y)\n",
    "                total_test_loss += test_loss.item()\n",
    "        \n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "        test_hist.append(avg_test_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1:2d}/{num_epochs} - Training Loss: {avg_loss:.4f}, Test Loss: {avg_test_loss:.4f}')\n",
    "        \n",
    "    x = np.linspace(1, num_epochs, num_epochs)\n",
    "    plt.plot(x, train_hist, scalex=True, label=\"Training loss\")\n",
    "    plt.plot(x, test_hist, label=\"Test loss\")\n",
    "    plt.legend()\n",
    "\n",
    "train_(model_, train_loader_, test_loader_)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac9f9f-5c9d-4e95-8af8-f9f7eace65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Forecasting\n",
    "def plot_forecasting(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    num_forecast_steps = 30\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(1, min(num_forecast_steps, len(X_test)) + 1):\n",
    "            input_tensor = X_test[-i].unsqueeze(0).to(device)\n",
    "            predicted = model(input_tensor, target_len)\n",
    "            forecasted_values = predicted.squeeze(0).cpu().numpy()\n",
    "            forecasted_values = scaler.inverse_transform(\n",
    "                forecasted_values.reshape(-1, 1)\n",
    "            ).flatten()\n",
    "            idx = test_data.index[-i - target_len + 1 : -i + 1 if i > 1 else None]\n",
    "            plt.plot(idx, forecasted_values, color=\"red\", alpha=0.6,\n",
    "                     label=\"forecasted values\" if i == 1 else \"\")\n",
    "            \n",
    "    plt.plot(test_data.index[-100:-39], test_data[-100:-39], label=\"test_data\", color=\"b\")\n",
    "    plt.plot(test_data.index[-39:], test_data.iloc[-39:], label=\"actual values\", color=\"green\")\n",
    "\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.title('Time Series Forecasting')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_forecasting(model_, X_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7613a-7668-4864-bb5d-336dd4f5ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test = X_test.to(device)\n",
    "        y_hat = model(X_test, target_len)\n",
    "        test_predictions = y_hat[:, :, 0]\n",
    "\n",
    "    test_predictions = test_predictions.cpu().numpy()\n",
    "    y_test = y_test.cpu().numpy().reshape(-1, target_len)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, test_predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, test_predictions)\n",
    "\n",
    "    return rmse, mape\n",
    "\n",
    "rmse, mape = test_(model_, X_test_, y_test_)\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MAPE: {mape:.4f}')\n",
    "\n",
    "# RMSE: 0.2088\n",
    "# MAPE: 0.1593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf7aad-8bdd-45cf-9b2c-e41e5df241d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182004f4-5d10-41ee-a68a-95d8da7b732e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
