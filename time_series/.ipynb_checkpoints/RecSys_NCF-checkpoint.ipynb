{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac020afc-675e-4704-8692-f49c586c6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch # 실습 환경에선 주석처리 가능.\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf2e6b-0d99-4c3b-8d3e-db2a5f58c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ac727-b6fd-466c-9f24-2202443cef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "# extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "# ratings_path = './ml-latest-small/ratings.csv' # need to fix\n",
    "ratings_path = '/content/ratings.csv'\n",
    "df = pd.read_csv(ratings_path)\n",
    "\n",
    "print(len(df)) # number of data\n",
    "print(df['userId'].nunique()) # number of users\n",
    "print(df['movieId'].nunique()) # number of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c6e51-dcf4-477c-bf06-e4ec3644d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fix\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5367f-b69a-4670-8226-738133833558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Collaborative filtering\n",
    "# 1.Data_preprocessing\n",
    "\n",
    "class MovieLens:\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    def __getitem__(self,item):\n",
    "        '''\n",
    "        item = randomly selected indexes for (user,item) pairs\n",
    "        '''\n",
    "        users = self.users[item]\n",
    "        movies = self.movies[item]\n",
    "        ratings = self.ratings[item]\n",
    "        return {'users': torch.tensor(users, dtype = torch.long).to(device),\n",
    "                'movies': torch.tensor(movies, dtype = torch.long).to(device),\n",
    "                'ratings': torch.tensor(ratings, dtype=torch.long).to(device)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb66cc-8f91-4567-b14d-5d46d0bd9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert actual index for user and items as consecutive integer\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "df.userID = lbl_user.fit_transform(df.userId.values)\n",
    "df.movieId = lbl_movie.fit_transform(df.movieId.values)\n",
    "df_train, df_test = model_selection.train_test_split(df, test_size=0.1, random_state=42, stratify=df.rating.values)\n",
    "\n",
    "train_dataset = MovieLens(users = df_train.userId.values, movies = df_train.movieId.values, ratings = df_train.rating.values)\n",
    "test_dataset = MovieLens(users = df_test.userId.values, movies = df_test.movieId.values, ratings = df_test.rating.values)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5fbbcc-4280-49f5-a6dd-b59c6b6d91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model setting\n",
    "### Embedding layer + NCF layer\n",
    "# 2-layer(including output layer)\n",
    "\n",
    "# hidden layer + active layer(RELU) + output\n",
    "# latent vector dim: 32\n",
    "# input dim: 64\n",
    "\n",
    "class Neural_Collaborative_Filtering(nn.Module):\n",
    "    def __init__(self, n_users, n_movies):\n",
    "        '''\n",
    "        n_users = # of users\n",
    "        n_movies = # of movies\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(n_users, 32)\n",
    "        self.movie_embedding = nn.Embedding(n_movies, 32)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64,32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self, users, movies, ratings = None):\n",
    "        user_embedding = self.user_embedding(users)\n",
    "        movie_embedding = self.movie_embedding(movies)\n",
    "        input_embedding = torch.cat([user_embedding, movie_embedding], dim=1)\n",
    "        \n",
    "        hidden_feature = self.fc1(input_embedding)\n",
    "        hidden_feature = self.relu(hidden_feature)\n",
    "        \n",
    "        output = self.fc2(hidden_feature)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81cc931-71b6-41aa-bf7d-4464ea6e1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size=128, shuffle=True, drop_last = False)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size=128, shuffle=True, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97069ceb-f2ea-408a-a8c6-4c1ed9803770",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Neural_Collaborative_Filtering(n_users = len(lbl_user.classes_), n_movies = len(lbl_movie.classes_)).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a3445-7da3-4a47-9dc5-f8adcaf4081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "total_loss = 0\n",
    "iter_cnt = 0\n",
    "all_losses_list = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, epoch+1):\n",
    "    total_loss =0\n",
    "    epoch_check=0\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        '''\n",
    "        train_data = {'users':[], 'items':[], 'ratings':[]}\n",
    "        '''\n",
    "        batch_size = len(train_data['users'])\n",
    "        prediction = model(train_data['users'], train_data['movies'])\n",
    "        ground_truth = train_data['ratings'].view(batch_size,-1).to(torch.float32)\n",
    "        \n",
    "        loss = loss_func(prediction, ground_truth)\n",
    "        total_loss = total_loss + (loss.item() * batch_size)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter_cnt = iter_cnt +1\n",
    "        epoch_check += batch_size\n",
    "        \n",
    "        if iter_cnt % 100 == 0 and iter_cnt !=0:\n",
    "            avg_iter_loss = loss.item()\n",
    "            batch_num = int((iter_cnt/100) % 7) if int((iter_cnt/100) % 7) else 7\n",
    "            print(f\"epoch {epoch} - (batch {batch_num}) loss : {(avg_iter_loss)}\")\n",
    "\n",
    "        if epoch_check % (batch_size * len(train_loader)) == 0 and epoch_check != 0:\n",
    "            avg_loss = total_loss / epoch_check\n",
    "            print(f\"Epoch {epoch} Avg_loss : {avg_loss}\")\n",
    "            all_losses_list.append(avg_loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b2ef2-a649-481a-89cb-bf1fbdf3b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Loss change\n",
    "plt.figure()\n",
    "\n",
    "title_font = {\n",
    "    'fontsize': 16,\n",
    "    'fontweight': 'bold'\n",
    "}\n",
    "\n",
    "plt.title('Loss change',fontdict=title_font)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.plot(all_losses_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d701e7-c843-40f5-9f97-8662915aad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_output_list = []\n",
    "target_output_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batched_data in enumerate(test_loader):\n",
    "        model_output = model(batched_data['users'], batched_data['movies'])\n",
    "        model_output_batch = model_output.cpu().numpy().squeeze(axis=1).tolist()\n",
    "        model_output_list += (model_output_batch)\n",
    "        \n",
    "        target_rating = batched_data['ratings']\n",
    "        target_rating_batch = target_rating.cpu().numpy().tolist()\n",
    "        target_rating_list += target_rating_batchatch\n",
    "        \n",
    "mse = mean_squared_error(target_rating_list, model_output_list)\n",
    "rms = np.sqrt(mse)\n",
    "\n",
    "print(f\"rms: {rms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3339cd0-4a14-4331-84c0-9e04b37c4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall@k & Precision@k\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "user_est_true = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batched_data enumerate(test_loader):\n",
    "        users = batch_data['users']\n",
    "        movies = batched_data['movies']\n",
    "        ratings = batched_data['ratings']\n",
    "        \n",
    "        model_output = model(batched_data['users'], batched_data['movies'])\n",
    "        \n",
    "        for i in range(len(users)):\n",
    "            user_id = users[i].item()\n",
    "            movie_id = movies[i].item()\n",
    "            pred_rating = model_output[i][0].item()\n",
    "            true_rating = ratings[i].item()\n",
    "                        \n",
    "            user_est_true[user_id].append((pred_rating, true_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b2ede-5806-4735-8944-dc94f4a925b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "\n",
    "    # recall@K\n",
    "    k= 10\n",
    "    threshold = 3.5 # relevant item criterion\n",
    "    \n",
    "    for user_id, user_ratings in user_est_true.items():\n",
    "        user_rating.sort(key=lambda x:x[0], reverse=True)\n",
    "        \n",
    "        n_real_relevant= sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        recommended_k = user_rating[:k]\n",
    "        \n",
    "        n_real_relevant_in_top_k = sum((true_r >= threshold) for (est, true_r) in recommended_k)\n",
    "    \n",
    "        # precision@k\n",
    "        precisions[user_id] = n_real_relevant_in_top_k / K # K=10\n",
    "        \n",
    "        # recall@k\n",
    "        if n_real_relevant:\n",
    "            recalls[user_id] = n_real_relevant_in_top_k / n_real_relevant\n",
    "        else:\n",
    "            recalls[user_id] = 0\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba1926-b8ca-40b1-bc6e-340ab7766b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and recall can then be averaged over all users\n",
    "print(f\"precision @ {k}: {sum(prec for prec in precisions.values()) / len(precisions)}\")\n",
    "\n",
    "print(f\"recall @ {k} : {sum(rec for rec in recalls.values()) / len(recalls)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
