{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc9d41-7cfe-4a84-bde7-d96c0b85cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accd4cc-0b79-4dc6-94c2-f1fdae3356cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdba746-49d1-4b01-9466-030aac63f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf0bfe6-26bb-4aff-9ab2-da5a56ea9e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d6497-4f85-4991-a4c4-9cd0609a9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "ratings_path = './ml-latest-small/ratings.csv'\n",
    "rating_df = pd.read_csv(ratings_path)\n",
    "print(len(rating_df))\n",
    "print(rating_df['userId'].nunique())\n",
    "print(rating_df['movieId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9d8da-897c-4489-a43e-6ee54ac28ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform UserID and MovieID into sequential indices\n",
    "\n",
    "user_encoder = {user: idx for idx, user in enumerate(rating_df['userId'].unique())}\n",
    "movie_encoder = {movie : idx for idx, movie in enumerate(rating_df['movieId'].unique())}\n",
    "\n",
    "rating_df['userId'] = rating_df['userId'].map(user_encoder)\n",
    "rating_df['movieId'] = rating_df['movieId'].map(movie_encoder)\n",
    "\n",
    "num_users = len(user_encoder)\n",
    "num_movies = len(movie_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41ed4a-f231-4330-b2e5-80c9b0f49582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for better replication\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053d177-c469-4a4d-abaf-6c1b9778c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph from Data\n",
    "\n",
    "# Convert Explicit interaction as Implicit interaction\n",
    "# Create Edge for Graph\n",
    "# Generate edge between user and movie when user rates movie higher than (or equal to) 1\n",
    "\n",
    "#### 중요!: Adjacency matrix 대신 edge_index를 넣어서도 GNN 연산이 가능하다 ####\n",
    "\n",
    "def create_edge_index(df, rating_threshold=1.0):\n",
    "    src, dst = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row['rating'] >= rating_threshold:\n",
    "            src.append(row['userId'])\n",
    "            # item indices after user indices\n",
    "            dst.append(row['movieId'] + num_users)\n",
    "            \n",
    "    return torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "edge_index = create_edge_index(rating_df)\n",
    "print(edge_index)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968526f-d902-43dc-9803-51d223b409b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices into train/val/test set (label for train/val/test set)\n",
    "train_indices, test_indices = train_test_split(range(edge_index.size(1)), test_size=0.2)\n",
    "val_indices, test_indices = train_test_split(test_indices, test_size=0.5)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b819e1-850e-442b-94d4-b3c3882a0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO : NGCF Layer 완성 ###\n",
    "\n",
    "class NGCFLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(input_dim, output_dim)\n",
    "        self.W2 = nn.Linear(input_dim, output_dim)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, edge_index, node_features, user_num, item_num):\n",
    "        '''\n",
    "        edge_index : 엣지 정보 (src, dst)의 집합.\n",
    "        node_features: node별 이전 layer에서 생성된 벡터 정보가 담긴 matrix (H^(l-1)) (|V| * d)\n",
    "        '''\n",
    "        \n",
    "        src, dst = edge_index\n",
    "        \n",
    "        deg = torch.zeros(node_features.size(0), device = node_features.device)\n",
    "        \n",
    "        deg.index_add_(0, src, torch.ones_like(src, dtype = torch.float))\n",
    "        \n",
    "        deg.index_add(0, dst, torch.ones_like(dst, dtype = torch.float))\n",
    "        \n",
    "        norm = 1.0/torch.sqrt(deg[src]*deg[dst])\n",
    "        \n",
    "        src_feat = node_features[src] # H_u\n",
    "        dst_feat = node_features[dst] # H_i\n",
    "        \n",
    "        # edge_messages for user(src) = m_(u<-i)) 결과 저장.\n",
    "        # Hint: step1. self.W1(h_i) + self.W2(h_u * h_i) 계산\n",
    "        # Hint: step2. 최종 m_(u<-i)를 위해선 앞선 norm을 앞서 계산한 message에 곱하기\n",
    "        edge_message_for_src = self.W1(dst_feat) + self.W2(dst_feat*src_feat)\n",
    "        edge_message_for_src *= norm.unsqueeze(1)\n",
    "        \n",
    "        # edge_messages for movie(dst) = m_(i<-u)) 결과 저장.\n",
    "        # Hint: step1. self.W1(h_u) + self.W2(h_i * h_u) 계산\n",
    "        # Hint: step2. 최종 m_(i<-u)를 위해선 앞선 norm을 앞서 계산한 message에 곱하기\n",
    "        edge_message_for_dst = self.W1(src_feat) + self.W2(src_feat*dst_feat)\n",
    "        edge_message_for_dst *= norm.unsqueeze(1)\n",
    "        \n",
    "        # aggregated_features = Combine()의 결과 저장.\n",
    "        aggregated_messages = torch.zeros_like(node_features)\n",
    " \n",
    "        # m_(u<-u) = self.W1(h_u) 계산해 더해주기\n",
    "        aggregated_messages.index_add(0, src, edge_messages_for_src)\n",
    "        aggregated_messages[:user_num] += self.W1(node_features[:user_num])\n",
    "        \n",
    "        # m_(i<-i) = self.W1(h_i) 계산해 더해주기\n",
    "        aggregated_messages.index_add_(0, dst, edge_messages_for_dst)\n",
    "        aggregated_messages[user_num:] += self.W1(node_features[user_num:])\n",
    "        \n",
    "        aggregated_features = self.leaky_relu(aggregated_messages)\n",
    "                \n",
    "        # engineering approach\n",
    "        # aggregated_features = self.dropout(aggregated_features)\n",
    "        return aggregated_features    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb929d9c-b47a-4b97-83bb-c0a1bb90ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, layer_dimes, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.node_embeddings = nn.Embedding(self.num_users+self.num_items, self.embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.node_embedding.weight)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            NGCFLayer(input_dim = (embedding_dim if i==0 else layer_dims[i -1]),\n",
    "                      output_dim=layer_dims[i], dropout=dropout)\n",
    "            for i in range(len(layer_dims))\n",
    "        ])\n",
    "        \n",
    "    def forward(self, edge_index):\n",
    "        node_features = self.node_embeddings.weight\n",
    "        layer_outputs = [node_features]\n",
    "        for layer in self.layers:\n",
    "            node_features = layer(edge_index, node_features,self.num_users, self.num_items)\n",
    "            layout_outputs.append(node_features)\n",
    "            \n",
    "        # Hint: NGCF의 final feature(representation)은 layer 별 feature에 대한 concatenated vector\n",
    "        # Hint: 최종 final feature matrix에는 [feuture_vector for users + feature_vector for items]가 들어있음.\n",
    "        final_features = torch.concat(layer_outputs,dim=-1)\n",
    "        user_features = final.features[:self.num_users]\n",
    "        item_features = final.features[self.num_users:]\n",
    "        return user_features, item_features\n",
    "    \n",
    "    def bpr_loss(self, user_emb, pos_item_emb, neg_item_emb, reg_weight=1e-4):\n",
    "        pos_scores = torch.sum(user_emb * pos_item_emb, dim=1)\n",
    "        neg_scores = torch.sum(user_emb * neg_item_emb, dim=1)\n",
    "        \n",
    "        loss = -torch.mean(F.losigmoid(pos_scores - neg_scores))\n",
    "        reg_loss = reg_weight * (user_emb.norm(2).pow(2) + pos_item_emb.norm(2).pow(2) + neg_item_emb.norm(2).pow(2)) / user_emb.size(0)\n",
    "        return loss + reg_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c67fa5-07fd-4ee1-9301-5d84aa5d9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(user_features, item_features, test_edge_index, k):\n",
    "    user_pos_items = defaultdict(list)\n",
    "    E_test = test_edge_index.size(1)\n",
    "    for i in range(E_test) :\n",
    "        u = test_edge_index[0,i].item()\n",
    "        it = test_edge_index[1, i].item() - num_users\n",
    "        user_pos_items[u].append(it)\n",
    "        \n",
    "    recall, precisions, ndcgs = [], [], []\n",
    "    \n",
    "    for user, pos_items in user_pos_items.items():\n",
    "        user_emb = user_features[user]\n",
    "        scores = torch.matmul(item_features, user_emb)\n",
    "        topk_scores, topk_indices = torch.topk(socres, k=k)\n",
    "        topk_indices = topk_indices.cpu().numpy().tolist()\n",
    "        \n",
    "        hits = 0\n",
    "        dcg = 0.0\n",
    "        idcg = 0.0\n",
    "        n_pos = len(pos_items)\n",
    "        \n",
    "        for rank, item_idx in enumerate(topk_indices):\n",
    "            if item_idx in pos_items:\n",
    "                hits += 1\n",
    "                dcg += 1.0 / math.log2(rank + 2)\n",
    "        for rank in range(min(n_pos, k)):\n",
    "            idcg += 1.0 / math.log2(rank + 2)\n",
    "        \n",
    "        recall_u = hits / n_pos\n",
    "        precision_u = hits / k\n",
    "        ndcg_u = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "        recalls.append(recall_u)\n",
    "        precisions.append(precision_u)\n",
    "        ndcgs.append(ndcg_u)\n",
    "\n",
    "    recall = np.mean(recalls)\n",
    "    precision = np.mean(precisions)\n",
    "    ndcg = np.mean(ndcgs)\n",
    "    return recall, precision, ndcg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf4587-103a-4df9-812d-32d35dcca365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_edge_index, val_edge_index, num_epochs, batch_size, device, k):\n",
    "    model.to(device)\n",
    "    train_edge_index = train_edge_index.to(device)\n",
    "    val_edge_index = val_edge_index.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = len(train_edge_index[0]) // batch_size\n",
    "        \n",
    "        for _ in range(num_batches):\n",
    "            indices = torch.randint(0, train_edge_index.size(1), (batch_size,), device=device)\n",
    "            user_indices = train_edge_index[0, indices]\n",
    "            pos_item_indices = train_edge_index[1, indices] - num_users\n",
    "            neg_item_indices = torch.randint(0, num_movies, (batch_size,), device=device)\n",
    "            \n",
    "            user_features, item_features = model(train_edge_index)\n",
    "            \n",
    "            u_emb = user_features[user_indices]\n",
    "            pos_emb = item_features[pos_item_indices]\n",
    "            neg_emb = item_features[neg_item_indices]\n",
    "            \n",
    "            loss = model.bpr_loss(u_emb, pos_emb, neg_emb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / num_batches:.4f}\")\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                \n",
    "            user_features, item_features = model(train_edge_index)\n",
    "            recall, precision, ndcg = evaluate(user_features.cpu(), item_features.cpu(), val_edge_index, k)\n",
    "            print(f\"[Validation] Epoch {epoch + 1}: Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}, NDCG@{k}: {ndcg:.4f}\")\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a284004-61ae-4e78-81e3-b8ff55f757e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, train_edge_index, test_edge_index, k, device):\n",
    "    model.eval()\n",
    "    train_edge_index = train_edge_index.to(device)\n",
    "    test_edge_index = test_edge_index.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        user_features, item_features = model(train_edge_index)\n",
    "\n",
    "    user_features = user_features.cpu()\n",
    "    item_features = item_features.cpu()\n",
    "    \n",
    "    recall, precision, ndcg = evaluate(user_features, item_features, test_edge_index, k)\n",
    "    recall = round(recall, 4)\n",
    "    precision = round(precision, 4)\n",
    "    ndcg = round(ndcg, 4)\n",
    "\n",
    "    print(f\"Recall@{k}: {recall:.4f}, Precision@{k}: {precision:.4f}, NDCG@{k}: {ndcg:.4f}\")\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc2d59-8bb2-463a-8b46-202f03309ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngcf_model = NGCF(num_users, num_movies, embedding_dim=64, layer_dims=[64, 64], dropout=0.1)\n",
    "optimizer_ngcf = torch.optim.Adam(ngcf_model.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"===== Train NGCF =====\")\n",
    "train(\n",
    "    model=ngcf_model,\n",
    "    optimizer = optimizer_ngcf,\n",
    "    train_edge_index = train_edge_index,\n",
    "    val_edge_index = val_edge_index,\n",
    "    num_epoch=30,\n",
    "    batch_size=1024,\n",
    "    device=device,\n",
    "    k=10    \n",
    ")\n",
    "\n",
    "print(\"===== Test NGCF =====\")\n",
    "test(\n",
    "    model = ngcf_model,\n",
    "    train_edge_index = train_edge_index\n",
    "    test_edge_index = test_edge_index\n",
    "    k=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8b2cd-b53d-4e0f-b866-0afe2ffe9739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
